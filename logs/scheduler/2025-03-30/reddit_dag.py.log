[2025-03-30T18:09:03.459+0000] {processor.py:186} INFO - Started process (PID=32) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:09:03.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:09:03.467+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:09:03.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:09:03.476+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:09:03.475+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:09:03.477+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:09:03.495+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.049 seconds
[2025-03-30T18:09:33.907+0000] {processor.py:186} INFO - Started process (PID=33) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:09:33.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:09:33.915+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:09:33.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:09:33.926+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:09:33.925+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:09:33.926+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:09:33.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.044 seconds
[2025-03-30T18:40:11.310+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:40:11.312+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:40:11.315+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:40:11.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:40:11.320+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:40:11.320+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:40:11.321+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:40:11.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.036 seconds
[2025-03-30T18:40:41.765+0000] {processor.py:186} INFO - Started process (PID=35) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:40:41.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:40:41.772+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:40:41.771+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:40:41.781+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:40:41.780+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:40:41.781+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:40:41.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.051 seconds
[2025-03-30T18:41:12.210+0000] {processor.py:186} INFO - Started process (PID=36) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:41:12.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:41:12.217+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:41:12.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:41:12.227+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:41:12.226+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:41:12.227+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:41:12.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.049 seconds
[2025-03-30T18:41:42.608+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:41:42.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:41:42.613+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:41:42.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:41:42.619+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:41:42.618+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:41:42.619+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:41:42.641+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.042 seconds
[2025-03-30T18:42:13.002+0000] {processor.py:186} INFO - Started process (PID=38) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:42:13.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:42:13.006+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:42:13.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:42:13.013+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:42:13.013+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:42:13.014+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:42:13.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.038 seconds
[2025-03-30T18:42:43.449+0000] {processor.py:186} INFO - Started process (PID=39) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:42:43.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:42:43.453+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:42:43.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:42:43.459+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:42:43.458+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:42:43.459+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:42:43.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.036 seconds
[2025-03-30T18:43:13.902+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:43:13.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:43:13.909+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:43:13.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:43:13.918+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:43:13.917+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:43:13.918+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:43:13.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.050 seconds
[2025-03-30T18:43:47.924+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:43:47.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:43:47.931+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:43:47.930+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:43:47.938+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:43:47.937+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:43:47.938+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:43:47.954+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.065 seconds
[2025-03-30T18:44:18.341+0000] {processor.py:186} INFO - Started process (PID=42) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:44:18.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:44:18.348+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:44:18.347+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:44:18.355+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:44:18.354+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:44:18.355+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:44:18.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.042 seconds
[2025-03-30T18:44:48.753+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:44:48.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:44:48.777+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:44:48.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:44:48.784+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:44:48.783+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:44:48.784+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:44:48.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.057 seconds
[2025-03-30T18:45:19.176+0000] {processor.py:186} INFO - Started process (PID=44) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:45:19.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:45:19.182+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:45:19.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:45:19.199+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:45:19.197+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:45:19.199+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:45:19.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.056 seconds
[2025-03-30T18:45:49.615+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:45:49.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:45:49.623+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:45:49.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:45:49.631+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:45:49.630+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:45:49.631+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:45:49.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.045 seconds
[2025-03-30T18:46:20.072+0000] {processor.py:186} INFO - Started process (PID=46) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:46:20.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:46:20.078+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:46:20.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:46:20.084+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:46:20.084+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:46:20.085+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:46:20.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.040 seconds
[2025-03-30T18:46:50.549+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:46:50.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:46:50.553+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:46:50.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:46:50.561+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:46:50.560+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:46:50.561+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:46:50.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.037 seconds
[2025-03-30T18:47:21.019+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:47:21.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:47:21.024+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:47:21.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:47:21.031+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:47:21.030+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:47:21.031+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:47:21.047+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.040 seconds
[2025-03-30T18:47:51.442+0000] {processor.py:186} INFO - Started process (PID=49) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:47:51.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:47:51.451+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:47:51.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:47:51.457+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:47:51.457+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:47:51.458+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:47:51.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.043 seconds
[2025-03-30T18:48:21.935+0000] {processor.py:186} INFO - Started process (PID=50) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:48:21.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:48:21.948+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:48:21.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:48:21.956+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:48:21.956+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:48:21.957+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:48:21.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.054 seconds
[2025-03-30T18:48:52.370+0000] {processor.py:186} INFO - Started process (PID=51) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:48:52.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T18:48:52.378+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:48:52.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:48:52.386+0000] {logging_mixin.py:190} INFO - [2025-03-30T18:48:52.386+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T18:48:52.387+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T18:48:52.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.050 seconds
[2025-03-30T19:05:16.313+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:05:16.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:05:16.319+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:05:16.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:05:16.325+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:05:16.324+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:05:16.325+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:05:16.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.056 seconds
[2025-03-30T19:13:08.972+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:13:08.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:13:08.976+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:13:08.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:13:08.982+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:13:08.981+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:13:08.982+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:13:08.994+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.032 seconds
[2025-03-30T19:13:39.388+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:13:39.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:13:39.393+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:13:39.392+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:13:39.399+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:13:39.399+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:13:39.399+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:13:39.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.052 seconds
[2025-03-30T19:14:09.823+0000] {processor.py:186} INFO - Started process (PID=55) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:14:09.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:14:09.828+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:14:09.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:14:09.834+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:14:09.833+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:14:09.834+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:14:09.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.038 seconds
[2025-03-30T19:14:40.270+0000] {processor.py:186} INFO - Started process (PID=56) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:14:40.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:14:40.276+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:14:40.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:14:40.283+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:14:40.282+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:14:40.283+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:14:40.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.056 seconds
[2025-03-30T19:15:10.721+0000] {processor.py:186} INFO - Started process (PID=57) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:15:10.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:15:10.728+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:15:10.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:15:10.737+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:15:10.736+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:15:10.737+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:15:10.755+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.048 seconds
[2025-03-30T19:15:41.217+0000] {processor.py:186} INFO - Started process (PID=58) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:15:41.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:15:41.222+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:15:41.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:15:41.228+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:15:41.228+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:15:41.229+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:15:41.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.053 seconds
[2025-03-30T19:16:11.608+0000] {processor.py:186} INFO - Started process (PID=59) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:16:11.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:16:11.612+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:16:11.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:16:11.618+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:16:11.617+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:16:11.618+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:16:11.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.035 seconds
[2025-03-30T19:16:42.034+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:16:42.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:16:42.039+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:16:42.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:16:42.046+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:16:42.045+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:16:42.046+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:16:42.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.042 seconds
[2025-03-30T19:17:12.424+0000] {processor.py:186} INFO - Started process (PID=61) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:17:12.425+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:17:12.429+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:17:12.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:17:12.435+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:17:12.434+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:17:12.435+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:17:12.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.037 seconds
[2025-03-30T19:17:42.817+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:17:42.820+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:17:42.822+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:17:42.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:17:42.827+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:17:42.827+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:17:42.828+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:17:42.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.033 seconds
[2025-03-30T19:18:13.289+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:18:13.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:18:13.294+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:18:13.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:18:13.300+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:18:13.299+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:18:13.301+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:18:13.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.051 seconds
[2025-03-30T19:18:43.715+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:18:43.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:18:43.719+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:18:43.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:18:43.726+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:18:43.725+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:18:43.726+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:18:43.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.038 seconds
[2025-03-30T19:19:14.135+0000] {processor.py:186} INFO - Started process (PID=65) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:19:14.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:19:14.141+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:19:14.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:19:14.148+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:19:14.148+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:19:14.149+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:19:14.169+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.048 seconds
[2025-03-30T19:19:44.535+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:19:44.536+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:19:44.539+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:19:44.539+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:19:44.547+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:19:44.546+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:19:44.547+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:19:44.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.040 seconds
[2025-03-30T19:20:14.847+0000] {processor.py:186} INFO - Started process (PID=67) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:20:14.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:20:14.853+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:20:14.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:20:14.860+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:20:14.859+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:20:14.861+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:20:14.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.063 seconds
[2025-03-30T19:20:45.155+0000] {processor.py:186} INFO - Started process (PID=68) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:20:45.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:20:45.161+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:20:45.161+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:20:45.177+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:20:45.176+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:20:45.177+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:20:45.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.082 seconds
[2025-03-30T19:21:21.161+0000] {processor.py:186} INFO - Started process (PID=33) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:21:21.165+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:21:21.166+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:21:21.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:21:21.171+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:21:21.170+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:21:21.171+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:21:21.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.029 seconds
[2025-03-30T19:21:51.873+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:21:51.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:21:51.904+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:21:51.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:21:51.958+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:21:51.950+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:21:51.958+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:21:52.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.374 seconds
[2025-03-30T19:22:22.341+0000] {processor.py:186} INFO - Started process (PID=35) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:22:22.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:22:22.347+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:22:22.347+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:22:22.353+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:22:22.353+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:22:22.353+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:22:22.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.262 seconds
[2025-03-30T19:22:54.476+0000] {processor.py:186} INFO - Started process (PID=36) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:22:54.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:22:54.652+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:22:54.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:22:54.864+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:22:54.847+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:22:54.866+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:22:55.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 1.222 seconds
[2025-03-30T19:23:29.615+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:23:29.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:23:30.143+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:23:30.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:23:30.804+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:23:30.767+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:23:30.806+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:23:31.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 3.174 seconds
[2025-03-30T19:24:02.630+0000] {processor.py:186} INFO - Started process (PID=38) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:24:02.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:24:02.687+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:24:02.685+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:24:02.764+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:24:02.760+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:24:02.765+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:24:03.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.538 seconds
[2025-03-30T19:24:34.474+0000] {processor.py:186} INFO - Started process (PID=39) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:24:34.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:24:34.676+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:24:34.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:24:34.838+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:24:34.818+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:24:34.839+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:24:35.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 1.025 seconds
[2025-03-30T19:25:10.508+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:25:10.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:25:11.072+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:25:11.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:25:11.771+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:25:11.692+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:25:11.785+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:25:13.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 5.083 seconds
[2025-03-30T19:25:46.175+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:25:46.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:25:46.887+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:25:46.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:25:47.424+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:25:47.325+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:25:47.439+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:25:49.422+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 4.269 seconds
[2025-03-30T19:26:19.726+0000] {processor.py:186} INFO - Started process (PID=42) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:26:19.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:26:19.738+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:26:19.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:26:19.752+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:26:19.751+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:26:19.752+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:26:19.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.087 seconds
[2025-03-30T19:26:50.109+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:26:50.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:26:50.116+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:26:50.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:26:50.124+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:26:50.123+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:26:50.125+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:26:50.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.061 seconds
[2025-03-30T19:27:20.554+0000] {processor.py:186} INFO - Started process (PID=44) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:27:20.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:27:20.561+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:27:20.560+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:27:20.568+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:27:20.567+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:27:20.569+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:27:20.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.047 seconds
[2025-03-30T19:27:51.014+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:27:51.015+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:27:51.020+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:27:51.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:27:51.030+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:27:51.029+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:27:51.030+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:27:51.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.073 seconds
[2025-03-30T19:28:21.495+0000] {processor.py:186} INFO - Started process (PID=46) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:28:21.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:28:21.512+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:28:21.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:28:21.524+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:28:21.523+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:28:21.524+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:28:21.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.059 seconds
[2025-03-30T19:28:51.956+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:28:51.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:28:51.961+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:28:51.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:28:51.968+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:28:51.967+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:28:51.968+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:28:51.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.040 seconds
[2025-03-30T19:29:22.400+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:29:22.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:29:22.407+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:29:22.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:29:22.414+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:29:22.413+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:29:22.414+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:29:22.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.055 seconds
[2025-03-30T19:29:52.781+0000] {processor.py:186} INFO - Started process (PID=49) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:29:52.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:29:52.788+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:29:52.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:29:52.797+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:29:52.796+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:29:52.797+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:29:52.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.053 seconds
[2025-03-30T19:30:23.147+0000] {processor.py:186} INFO - Started process (PID=50) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:30:23.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:30:23.152+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:30:23.152+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:30:23.160+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:30:23.159+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:30:23.160+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:30:23.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.059 seconds
[2025-03-30T19:30:53.630+0000] {processor.py:186} INFO - Started process (PID=51) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:30:53.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:30:53.636+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:30:53.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:30:53.642+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:30:53.641+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:30:53.642+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:30:53.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.050 seconds
[2025-03-30T19:31:24.029+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:31:24.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:31:24.035+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:31:24.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:31:24.042+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:31:24.041+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:31:24.042+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:31:24.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.044 seconds
[2025-03-30T19:31:54.474+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:31:54.475+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:31:54.479+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:31:54.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:31:54.485+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:31:54.484+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:31:54.485+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:31:54.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.043 seconds
[2025-03-30T19:32:24.923+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:32:24.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:32:24.929+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:32:24.929+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:32:24.936+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:32:24.936+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:32:24.937+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:32:24.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.049 seconds
[2025-03-30T19:32:55.901+0000] {processor.py:186} INFO - Started process (PID=33) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:32:55.902+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:32:55.904+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:32:55.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:32:55.908+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:32:55.907+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:32:55.908+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:32:55.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.023 seconds
[2025-03-30T19:33:26.289+0000] {processor.py:186} INFO - Started process (PID=34) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:33:26.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:33:26.293+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:33:26.293+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:33:26.299+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:33:26.298+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:33:26.299+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:33:26.313+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.030 seconds
[2025-03-30T19:33:56.614+0000] {processor.py:186} INFO - Started process (PID=35) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:33:56.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:33:56.620+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:33:56.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:33:56.627+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:33:56.626+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:33:56.627+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:33:56.651+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.048 seconds
[2025-03-30T19:34:26.983+0000] {processor.py:186} INFO - Started process (PID=36) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:34:26.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:34:26.989+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:34:26.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:34:27.003+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:34:27.001+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:34:27.003+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:34:27.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.058 seconds
[2025-03-30T19:34:57.341+0000] {processor.py:186} INFO - Started process (PID=37) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:34:57.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:34:57.348+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:34:57.348+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:34:57.360+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:34:57.358+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:34:57.361+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:34:57.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.048 seconds
[2025-03-30T19:35:27.721+0000] {processor.py:186} INFO - Started process (PID=38) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:35:27.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:35:27.727+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:35:27.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:35:27.735+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:35:27.734+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:35:27.735+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:35:27.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.037 seconds
[2025-03-30T19:35:58.089+0000] {processor.py:186} INFO - Started process (PID=39) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:35:58.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:35:58.094+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:35:58.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:35:58.101+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:35:58.101+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:35:58.102+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:35:58.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.038 seconds
[2025-03-30T19:36:28.450+0000] {processor.py:186} INFO - Started process (PID=40) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:36:28.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:36:28.454+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:36:28.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:36:28.462+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:36:28.461+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:36:28.462+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:36:28.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.037 seconds
[2025-03-30T19:36:58.813+0000] {processor.py:186} INFO - Started process (PID=41) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:36:58.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:36:58.819+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:36:58.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:36:58.825+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:36:58.824+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:36:58.825+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:36:58.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.037 seconds
[2025-03-30T19:37:29.154+0000] {processor.py:186} INFO - Started process (PID=42) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:37:29.154+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:37:29.156+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:37:29.156+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:37:29.162+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:37:29.161+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:37:29.162+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:37:29.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.027 seconds
[2025-03-30T19:37:59.532+0000] {processor.py:186} INFO - Started process (PID=43) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:37:59.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:37:59.535+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:37:59.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:37:59.540+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:37:59.539+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:37:59.540+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:37:59.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.031 seconds
[2025-03-30T19:38:29.834+0000] {processor.py:186} INFO - Started process (PID=44) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:38:29.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:38:29.847+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:38:29.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:38:29.862+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:38:29.861+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:38:29.863+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:38:29.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.053 seconds
[2025-03-30T19:39:00.139+0000] {processor.py:186} INFO - Started process (PID=45) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:39:00.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:39:00.144+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:39:00.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:39:00.151+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:39:00.150+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:39:00.151+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:39:00.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.038 seconds
[2025-03-30T19:39:30.456+0000] {processor.py:186} INFO - Started process (PID=46) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:39:30.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:39:30.462+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:39:30.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:39:30.480+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:39:30.478+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:39:30.480+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:39:30.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.055 seconds
[2025-03-30T19:40:00.794+0000] {processor.py:186} INFO - Started process (PID=47) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:40:00.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:40:00.798+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:40:00.798+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:40:00.803+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:40:00.802+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:40:00.803+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:40:00.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.030 seconds
[2025-03-30T19:40:31.166+0000] {processor.py:186} INFO - Started process (PID=48) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:40:31.167+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:40:31.172+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:40:31.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:40:31.180+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:40:31.179+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:40:31.180+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:40:31.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.043 seconds
[2025-03-30T19:41:01.567+0000] {processor.py:186} INFO - Started process (PID=49) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:41:01.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:41:01.573+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:41:01.572+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:41:01.579+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:41:01.578+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:41:01.579+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:41:01.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.038 seconds
[2025-03-30T19:41:10.718+0000] {processor.py:186} INFO - Started process (PID=50) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:41:10.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:41:10.723+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:41:10.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:41:10.809+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:41:10.810+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:41:10.842+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 11, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:41:10.842+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:41:10.987+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:41:10.986+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 44, in <module>
    python_callable=upload_s3_pipeline,
NameError: name 'upload_s3_pipeline' is not defined
[2025-03-30T19:41:10.987+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:41:11.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.303 seconds
[2025-03-30T19:41:25.954+0000] {processor.py:186} INFO - Started process (PID=52) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:41:25.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:41:25.960+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:41:25.960+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:41:25.969+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:41:25.968+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:41:25.969+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:41:25.998+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.055 seconds
[2025-03-30T19:41:56.346+0000] {processor.py:186} INFO - Started process (PID=53) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:41:56.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:41:56.350+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:41:56.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:41:56.355+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:41:56.354+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.aws_s3_pipeline import upload_s3_pipeline
ModuleNotFoundError: No module named 'pipelines.aws_s3_pipeline'
[2025-03-30T19:41:56.355+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:41:56.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.040 seconds
[2025-03-30T19:42:06.481+0000] {processor.py:186} INFO - Started process (PID=54) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:42:06.482+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:42:06.485+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:42:06.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:42:06.534+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 9, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:42:06.534+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:42:06.560+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 9, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:42:06.561+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:42:06.662+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:42:06.661+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 42, in <module>
    python_callable=upload_s3_pipeline,
NameError: name 'upload_s3_pipeline' is not defined
[2025-03-30T19:42:06.662+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:42:06.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.203 seconds
[2025-03-30T19:42:12.564+0000] {processor.py:186} INFO - Started process (PID=56) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:42:12.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:42:12.568+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:42:12.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:42:12.596+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:42:12.596+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:42:12.616+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:42:12.617+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:42:12.689+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:42:12.689+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 43, in <module>
    python_callable=upload_s3_pipeline,
NameError: name 'upload_s3_pipeline' is not defined
[2025-03-30T19:42:12.690+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:42:12.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.143 seconds
[2025-03-30T19:42:42.887+0000] {processor.py:186} INFO - Started process (PID=58) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:42:42.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:42:42.892+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:42:42.891+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:42:42.935+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:42:42.936+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:42:42.959+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:42:42.959+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:42:43.043+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:42:43.042+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 43, in <module>
    python_callable=upload_s3_pipeline,
NameError: name 'upload_s3_pipeline' is not defined
[2025-03-30T19:42:43.043+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:42:43.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.174 seconds
[2025-03-30T19:43:13.326+0000] {processor.py:186} INFO - Started process (PID=60) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:43:13.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:43:13.338+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:13.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:43:13.389+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:43:13.389+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:43:13.416+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:43:13.416+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:43:13.526+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:13.526+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 43, in <module>
    python_callable=upload_s3_pipeline,
NameError: name 'upload_s3_pipeline' is not defined
[2025-03-30T19:43:13.526+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:43:13.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.224 seconds
[2025-03-30T19:43:22.468+0000] {processor.py:186} INFO - Started process (PID=62) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:43:22.469+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:43:22.474+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:22.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:43:22.515+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:43:22.515+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:43:22.541+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:43:22.541+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:43:22.648+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:43:22.741+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:22.740+0000] {override.py:1930} INFO - Created Permission View: can read on DAG:etl_reddit_pipeline
[2025-03-30T19:43:22.745+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:22.745+0000] {override.py:1930} INFO - Created Permission View: can delete on DAG:etl_reddit_pipeline
[2025-03-30T19:43:22.747+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:22.747+0000] {override.py:1930} INFO - Created Permission View: can edit on DAG:etl_reddit_pipeline
[2025-03-30T19:43:22.749+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:22.749+0000] {override.py:1930} INFO - Created Permission View: can create on DAG Run:etl_reddit_pipeline
[2025-03-30T19:43:22.751+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:22.751+0000] {override.py:1930} INFO - Created Permission View: can read on DAG Run:etl_reddit_pipeline
[2025-03-30T19:43:22.752+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:22.752+0000] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:etl_reddit_pipeline
[2025-03-30T19:43:22.754+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:22.754+0000] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:etl_reddit_pipeline
[2025-03-30T19:43:22.755+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:22.754+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T19:43:22.761+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:22.761+0000] {dag.py:3262} INFO - Creating ORM DAG for etl_reddit_pipeline
[2025-03-30T19:43:22.766+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:22.766+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-29 00:00:00+00:00, run_after=2025-03-30 00:00:00+00:00
[2025-03-30T19:43:22.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.335 seconds
[2025-03-30T19:43:53.001+0000] {processor.py:186} INFO - Started process (PID=64) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:43:53.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:43:53.023+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:53.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:43:53.065+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:43:53.065+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:43:53.090+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:43:53.091+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:43:53.204+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:43:53.219+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:53.219+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T19:43:53.231+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:53.231+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-29 00:00:00+00:00, run_after=2025-03-30 00:00:00+00:00
[2025-03-30T19:43:53.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.249 seconds
[2025-03-30T19:43:58.177+0000] {processor.py:186} INFO - Started process (PID=66) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:43:58.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:43:58.183+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:58.183+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:43:58.229+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:43:58.229+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:43:58.255+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:43:58.255+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:43:58.361+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:43:58.435+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:58.435+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T19:43:58.445+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:43:58.445+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T19:43:58.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.289 seconds
[2025-03-30T19:44:28.693+0000] {processor.py:186} INFO - Started process (PID=68) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:44:28.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:44:28.699+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:44:28.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:44:28.748+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:44:28.748+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:44:28.774+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:44:28.775+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:44:28.900+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:44:28.923+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:44:28.922+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T19:44:28.935+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:44:28.934+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T19:44:28.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.264 seconds
[2025-03-30T19:44:59.068+0000] {processor.py:186} INFO - Started process (PID=70) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:44:59.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:44:59.074+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:44:59.073+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:44:59.129+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:44:59.129+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:44:59.156+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:44:59.157+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:44:59.249+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:44:59.277+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:44:59.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T19:44:59.289+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:44:59.289+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T19:44:59.296+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.239 seconds
[2025-03-30T19:45:29.558+0000] {processor.py:186} INFO - Started process (PID=72) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:45:29.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:45:29.564+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:45:29.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:45:29.607+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:45:29.608+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:45:29.638+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:45:29.638+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:45:29.730+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:45:29.745+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:45:29.745+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T19:45:29.756+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:45:29.756+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T19:45:29.764+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.216 seconds
[2025-03-30T19:45:59.889+0000] {processor.py:186} INFO - Started process (PID=74) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:45:59.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:45:59.893+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:45:59.893+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:45:59.940+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:45:59.940+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:45:59.969+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:45:59.969+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:46:00.072+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:46:00.087+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:46:00.087+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T19:46:00.098+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:46:00.098+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T19:46:00.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.226 seconds
[2025-03-30T19:46:30.378+0000] {processor.py:186} INFO - Started process (PID=76) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:46:30.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:46:30.382+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:46:30.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:46:30.409+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:46:30.409+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:46:30.428+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:46:30.428+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:46:30.503+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:46:30.514+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:46:30.513+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T19:46:30.523+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:46:30.523+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T19:46:30.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.158 seconds
[2025-03-30T19:47:00.769+0000] {processor.py:186} INFO - Started process (PID=78) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:47:00.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:47:00.776+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:47:00.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:47:00.821+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:47:00.821+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:47:00.850+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:47:00.850+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:47:00.951+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:47:00.965+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:47:00.965+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T19:47:00.977+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:47:00.976+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T19:47:00.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.234 seconds
[2025-03-30T19:47:31.173+0000] {processor.py:186} INFO - Started process (PID=80) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:47:31.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:47:31.178+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:47:31.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:47:31.214+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:47:31.214+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:47:31.239+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:47:31.240+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:47:31.329+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:47:31.343+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:47:31.343+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T19:47:31.354+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:47:31.354+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T19:47:31.361+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.201 seconds
[2025-03-30T19:48:01.649+0000] {processor.py:186} INFO - Started process (PID=82) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:48:01.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T19:48:01.654+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:48:01.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:48:01.705+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:48:01.705+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:48:01.739+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T19:48:01.739+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T19:48:01.832+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T19:48:01.849+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:48:01.849+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T19:48:01.860+0000] {logging_mixin.py:190} INFO - [2025-03-30T19:48:01.860+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T19:48:01.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.229 seconds
[2025-03-30T20:03:32.982+0000] {processor.py:186} INFO - Started process (PID=84) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T20:03:32.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T20:03:32.984+0000] {logging_mixin.py:190} INFO - [2025-03-30T20:03:32.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T20:03:33.003+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T20:03:33.003+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T20:03:33.022+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T20:03:33.022+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T20:03:33.099+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T20:03:33.111+0000] {logging_mixin.py:190} INFO - [2025-03-30T20:03:33.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T20:03:33.121+0000] {logging_mixin.py:190} INFO - [2025-03-30T20:03:33.121+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T20:03:33.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.150 seconds
[2025-03-30T21:24:38.574+0000] {processor.py:186} INFO - Started process (PID=86) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:24:38.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T21:24:38.577+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:24:38.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:24:38.625+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:24:38.625+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:24:38.662+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:24:38.662+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:24:38.756+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:24:38.770+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:24:38.770+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T21:24:38.781+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:24:38.781+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T21:24:38.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.219 seconds
[2025-03-30T21:53:19.446+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:53:19.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T21:53:19.451+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:53:19.450+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:53:19.490+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:53:19.490+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:53:19.527+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:53:19.527+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:53:19.619+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:53:19.635+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:53:19.635+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T21:53:19.647+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:53:19.647+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T21:53:19.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.221 seconds
[2025-03-30T21:53:49.818+0000] {processor.py:186} INFO - Started process (PID=90) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:53:49.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T21:53:49.832+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:53:49.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:53:49.876+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:53:49.877+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:53:49.922+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:53:49.922+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:53:50.037+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:53:50.054+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:53:50.054+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T21:53:50.070+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:53:50.070+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T21:53:50.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.278 seconds
[2025-03-30T21:54:20.309+0000] {processor.py:186} INFO - Started process (PID=92) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:54:20.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T21:54:20.315+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:54:20.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:54:20.355+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:54:20.356+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:54:20.390+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:54:20.390+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:54:20.485+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:54:20.501+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:54:20.501+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T21:54:20.514+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:54:20.514+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T21:54:20.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.223 seconds
[2025-03-30T21:54:50.767+0000] {processor.py:186} INFO - Started process (PID=94) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:54:50.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T21:54:50.772+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:54:50.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:54:50.810+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:54:50.810+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:54:50.838+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:54:50.838+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:54:50.956+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:54:50.972+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:54:50.972+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T21:54:50.984+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:54:50.984+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T21:54:50.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.238 seconds
[2025-03-30T21:55:21.108+0000] {processor.py:186} INFO - Started process (PID=96) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:55:21.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T21:55:21.113+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:55:21.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:55:21.159+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:55:21.159+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:55:21.188+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:55:21.188+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:55:21.286+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:55:21.301+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:55:21.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T21:55:21.312+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:55:21.312+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T21:55:21.320+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.225 seconds
[2025-03-30T21:55:51.643+0000] {processor.py:186} INFO - Started process (PID=98) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:55:51.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T21:55:51.649+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:55:51.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:55:51.705+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:55:51.705+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:55:51.734+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:55:51.734+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:55:51.845+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:55:51.860+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:55:51.860+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T21:55:51.871+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:55:51.871+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T21:55:51.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.245 seconds
[2025-03-30T21:56:22.040+0000] {processor.py:186} INFO - Started process (PID=100) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:56:22.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T21:56:22.047+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:56:22.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:56:22.095+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:56:22.095+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:56:22.125+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:56:22.125+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:56:22.227+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:56:22.241+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:56:22.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T21:56:22.252+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:56:22.252+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T21:56:22.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.229 seconds
[2025-03-30T21:56:52.484+0000] {processor.py:186} INFO - Started process (PID=102) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:56:52.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T21:56:52.489+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:56:52.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:56:52.524+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:56:52.524+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:56:52.549+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:56:52.549+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:56:52.633+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:56:52.645+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:56:52.645+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T21:56:52.655+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:56:52.655+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T21:56:52.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.188 seconds
[2025-03-30T21:57:22.916+0000] {processor.py:186} INFO - Started process (PID=104) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:57:22.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T21:57:22.922+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:57:22.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:57:22.963+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:57:22.963+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:57:23.000+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:57:23.001+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:57:23.101+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:57:23.116+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:57:23.116+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T21:57:23.127+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:57:23.127+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T21:57:23.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.230 seconds
[2025-03-30T21:57:53.365+0000] {processor.py:186} INFO - Started process (PID=106) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:57:53.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T21:57:53.377+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:57:53.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:57:53.412+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:57:53.412+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:57:53.438+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:57:53.438+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:57:53.547+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:57:53.566+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:57:53.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T21:57:53.577+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:57:53.577+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T21:57:53.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.244 seconds
[2025-03-30T21:58:23.720+0000] {processor.py:186} INFO - Started process (PID=108) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:58:23.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T21:58:23.727+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:58:23.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:58:23.779+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:58:23.780+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:58:23.806+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:58:23.806+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:58:23.913+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:58:23.929+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:58:23.929+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T21:58:23.939+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:58:23.939+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T21:58:23.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.240 seconds
[2025-03-30T21:58:54.260+0000] {processor.py:186} INFO - Started process (PID=110) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:58:54.264+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T21:58:54.274+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:58:54.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:58:54.322+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:58:54.323+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:58:54.355+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:58:54.356+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:58:54.447+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:58:54.465+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:58:54.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T21:58:54.476+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:58:54.476+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T21:58:54.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.251 seconds
[2025-03-30T21:59:24.662+0000] {processor.py:186} INFO - Started process (PID=112) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:59:24.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T21:59:24.670+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:59:24.669+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:59:24.714+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:59:24.714+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:59:24.753+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:59:24.753+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:59:24.847+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:59:24.884+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:59:24.884+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T21:59:24.897+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:59:24.896+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T21:59:24.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.267 seconds
[2025-03-30T21:59:55.162+0000] {processor.py:186} INFO - Started process (PID=114) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:59:55.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T21:59:55.170+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:59:55.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:59:55.229+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:59:55.229+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:59:55.260+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T21:59:55.260+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T21:59:55.367+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T21:59:55.383+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:59:55.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T21:59:55.393+0000] {logging_mixin.py:190} INFO - [2025-03-30T21:59:55.393+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T21:59:55.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.253 seconds
[2025-03-30T22:00:25.567+0000] {processor.py:186} INFO - Started process (PID=116) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:00:25.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:00:25.574+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:00:25.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:00:25.611+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:00:25.611+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:00:25.638+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:00:25.639+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:00:25.739+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:00:25.757+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:00:25.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:00:25.769+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:00:25.768+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:00:25.776+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.221 seconds
[2025-03-30T22:00:56.149+0000] {processor.py:186} INFO - Started process (PID=118) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:00:56.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:00:56.155+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:00:56.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:00:56.221+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:00:56.222+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:00:56.266+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:00:56.267+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:00:56.380+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:00:56.397+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:00:56.397+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:00:56.412+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:00:56.412+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:00:56.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.280 seconds
[2025-03-30T22:01:26.486+0000] {processor.py:186} INFO - Started process (PID=120) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:01:26.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:01:26.491+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:01:26.491+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:01:26.529+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:01:26.530+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:01:26.565+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:01:26.566+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:01:26.657+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:01:26.677+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:01:26.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:01:26.693+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:01:26.693+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:01:26.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.233 seconds
[2025-03-30T22:01:56.805+0000] {processor.py:186} INFO - Started process (PID=122) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:01:56.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:01:56.811+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:01:56.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:01:56.868+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:01:56.868+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:01:56.896+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:01:56.896+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:01:57.007+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:01:57.026+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:01:57.026+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:01:57.039+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:01:57.039+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:01:57.047+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.255 seconds
[2025-03-30T22:02:27.411+0000] {processor.py:186} INFO - Started process (PID=124) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:02:27.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:02:27.416+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:02:27.416+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:02:27.454+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:02:27.454+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:02:27.495+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:02:27.496+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:02:27.587+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:02:27.607+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:02:27.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:02:27.619+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:02:27.619+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:02:27.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.248 seconds
[2025-03-30T22:02:57.762+0000] {processor.py:186} INFO - Started process (PID=126) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:02:57.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:02:57.767+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:02:57.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:02:57.813+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:02:57.813+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:02:57.844+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:02:57.844+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:02:57.952+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:02:57.970+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:02:57.970+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:02:57.981+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:02:57.981+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:02:57.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.236 seconds
[2025-03-30T22:03:28.428+0000] {processor.py:186} INFO - Started process (PID=128) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:03:28.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:03:28.433+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:03:28.433+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:03:28.499+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:03:28.499+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:03:28.554+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:03:28.555+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:03:28.679+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:03:28.711+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:03:28.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:03:28.728+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:03:28.727+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:03:28.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.341 seconds
[2025-03-30T22:03:59.097+0000] {processor.py:186} INFO - Started process (PID=130) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:03:59.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:03:59.103+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:03:59.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:03:59.159+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:03:59.159+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:03:59.211+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:03:59.211+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:03:59.309+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:03:59.328+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:03:59.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:03:59.340+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:03:59.340+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:03:59.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.268 seconds
[2025-03-30T22:04:29.488+0000] {processor.py:186} INFO - Started process (PID=132) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:04:29.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:04:29.495+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:04:29.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:04:29.538+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:04:29.538+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:04:29.567+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:04:29.568+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:04:29.685+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:04:29.702+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:04:29.702+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:04:29.713+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:04:29.713+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:04:29.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.247 seconds
[2025-03-30T22:05:00.061+0000] {processor.py:186} INFO - Started process (PID=134) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:05:00.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:05:00.065+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:05:00.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:05:00.112+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:05:00.113+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:05:00.143+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:05:00.143+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:05:00.243+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:05:00.261+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:05:00.261+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:05:00.273+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:05:00.273+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:05:00.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.249 seconds
[2025-03-30T22:05:30.465+0000] {processor.py:186} INFO - Started process (PID=136) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:05:30.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:05:30.468+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:05:30.468+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:05:30.502+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:05:30.503+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:05:30.548+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:05:30.549+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:05:30.656+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:05:30.674+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:05:30.674+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:05:30.686+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:05:30.685+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:05:30.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.238 seconds
[2025-03-30T22:06:00.993+0000] {processor.py:186} INFO - Started process (PID=138) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:06:00.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:06:00.998+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:06:00.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:06:01.047+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:06:01.047+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:06:01.085+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:06:01.086+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:06:01.186+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:06:01.204+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:06:01.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:06:01.225+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:06:01.224+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:06:01.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.250 seconds
[2025-03-30T22:06:31.350+0000] {processor.py:186} INFO - Started process (PID=140) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:06:31.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:06:31.357+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:06:31.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:06:31.408+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:06:31.409+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:06:31.439+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:06:31.439+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:06:31.561+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:06:31.578+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:06:31.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:06:31.594+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:06:31.594+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:06:31.606+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.272 seconds
[2025-03-30T22:07:01.949+0000] {processor.py:186} INFO - Started process (PID=142) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:07:01.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:07:01.955+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:07:01.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:07:02.005+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:07:02.006+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:07:02.038+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:07:02.038+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:07:02.143+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:07:02.161+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:07:02.161+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:07:02.173+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:07:02.173+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:07:02.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.245 seconds
[2025-03-30T22:07:32.346+0000] {processor.py:186} INFO - Started process (PID=144) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:07:32.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:07:32.359+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:07:32.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:07:32.398+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:07:32.398+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:07:32.434+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:07:32.434+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:07:32.530+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:07:32.547+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:07:32.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:07:32.564+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:07:32.564+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:07:32.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.246 seconds
[2025-03-30T22:08:02.989+0000] {processor.py:186} INFO - Started process (PID=146) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:08:02.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:08:02.993+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:08:02.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:08:03.041+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:08:03.041+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:08:03.072+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:08:03.072+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:08:03.177+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:08:03.196+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:08:03.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:08:03.207+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:08:03.207+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:08:03.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.255 seconds
[2025-03-30T22:08:33.357+0000] {processor.py:186} INFO - Started process (PID=148) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:08:33.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:08:33.365+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:08:33.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:08:33.409+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:08:33.409+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:08:33.442+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:08:33.442+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:08:33.541+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:08:33.571+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:08:33.571+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:08:33.582+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:08:33.582+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:08:33.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.248 seconds
[2025-03-30T22:09:04.107+0000] {processor.py:186} INFO - Started process (PID=150) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:09:04.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:09:04.115+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:09:04.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:09:04.173+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:09:04.173+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:09:04.217+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:09:04.217+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:09:04.316+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:09:04.334+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:09:04.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:09:04.346+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:09:04.346+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:09:04.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.261 seconds
[2025-03-30T22:09:34.561+0000] {processor.py:186} INFO - Started process (PID=152) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:09:34.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:09:34.567+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:09:34.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:09:34.613+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:09:34.613+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:09:34.651+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:09:34.652+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:09:34.753+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:09:34.778+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:09:34.778+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:09:34.790+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:09:34.790+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:09:34.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.267 seconds
[2025-03-30T22:10:05.134+0000] {processor.py:186} INFO - Started process (PID=154) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:10:05.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:10:05.141+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:10:05.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:10:05.198+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:10:05.198+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:10:05.249+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:10:05.250+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:10:05.367+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:10:05.384+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:10:05.384+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:10:05.396+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:10:05.395+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:10:05.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.292 seconds
[2025-03-30T22:10:35.524+0000] {processor.py:186} INFO - Started process (PID=156) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:10:35.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:10:35.532+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:10:35.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:10:35.591+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:10:35.591+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:10:35.622+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:10:35.623+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:10:35.743+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:10:35.759+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:10:35.759+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:10:35.771+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:10:35.771+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:10:35.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.271 seconds
[2025-03-30T22:11:06.176+0000] {processor.py:186} INFO - Started process (PID=158) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:11:06.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:11:06.190+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:11:06.189+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:11:06.230+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:11:06.230+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:11:06.270+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:11:06.272+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:11:06.378+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:11:06.394+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:11:06.394+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:11:06.407+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:11:06.407+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:11:06.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.264 seconds
[2025-03-30T22:11:36.587+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:11:36.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:11:36.606+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:11:36.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:11:36.647+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:11:36.647+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:11:36.679+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:11:36.679+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:11:36.791+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:11:36.806+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:11:36.806+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:11:36.818+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:11:36.818+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:11:36.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.261 seconds
[2025-03-30T22:12:07.177+0000] {processor.py:186} INFO - Started process (PID=162) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:12:07.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:12:07.182+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:12:07.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:12:07.239+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:12:07.240+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:12:07.271+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:12:07.271+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:12:07.393+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:12:07.410+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:12:07.410+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:12:07.422+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:12:07.422+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:12:07.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.265 seconds
[2025-03-30T22:12:37.636+0000] {processor.py:186} INFO - Started process (PID=164) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:12:37.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:12:37.643+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:12:37.642+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:12:37.692+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:12:37.692+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:12:37.741+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:12:37.741+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:12:37.858+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:12:37.877+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:12:37.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:12:37.891+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:12:37.890+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:12:37.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.284 seconds
[2025-03-30T22:13:08.172+0000] {processor.py:186} INFO - Started process (PID=166) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:13:08.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:13:08.178+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:13:08.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:13:08.219+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:13:08.219+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:13:08.252+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:13:08.252+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:13:08.372+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:13:08.398+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:13:08.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:13:08.411+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:13:08.411+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:13:08.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.263 seconds
[2025-03-30T22:13:38.660+0000] {processor.py:186} INFO - Started process (PID=168) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:13:38.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:13:38.667+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:13:38.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:13:38.726+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:13:38.726+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:13:38.775+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:13:38.776+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:13:38.895+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:13:38.915+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:13:38.915+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:13:38.941+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:13:38.941+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:13:38.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.303 seconds
[2025-03-30T22:14:09.225+0000] {processor.py:186} INFO - Started process (PID=170) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:14:09.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:14:09.243+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:14:09.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:14:09.300+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:14:09.301+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:14:09.340+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:14:09.340+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:14:09.450+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:14:09.469+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:14:09.468+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:14:09.484+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:14:09.484+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:14:09.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.283 seconds
[2025-03-30T22:14:39.719+0000] {processor.py:186} INFO - Started process (PID=172) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:14:39.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:14:39.725+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:14:39.725+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:14:39.784+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:14:39.784+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:14:39.819+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:14:39.819+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:14:39.933+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:14:39.949+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:14:39.949+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:14:39.966+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:14:39.966+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:14:39.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.299 seconds
[2025-03-30T22:15:10.224+0000] {processor.py:186} INFO - Started process (PID=174) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:15:10.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:15:10.234+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:15:10.233+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:15:10.295+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:15:10.296+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:15:10.331+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:15:10.331+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:15:10.443+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:15:10.464+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:15:10.464+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:15:10.490+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:15:10.490+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:15:10.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.308 seconds
[2025-03-30T22:15:40.730+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:15:40.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:15:40.736+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:15:40.736+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:15:40.789+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:15:40.789+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:15:40.824+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:15:40.824+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:15:40.947+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:15:40.963+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:15:40.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:15:40.977+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:15:40.977+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:15:40.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.268 seconds
[2025-03-30T22:16:11.307+0000] {processor.py:186} INFO - Started process (PID=178) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:16:11.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:16:11.312+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:16:11.312+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:16:11.370+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:16:11.370+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:16:11.400+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:16:11.401+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:16:11.517+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:16:11.536+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:16:11.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:16:11.548+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:16:11.548+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:16:11.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.261 seconds
[2025-03-30T22:16:41.745+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:16:41.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:16:41.751+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:16:41.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:16:41.814+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:16:41.814+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:16:41.849+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:16:41.849+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:16:41.970+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:16:41.990+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:16:41.990+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:16:42.016+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:16:42.015+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:16:42.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.291 seconds
[2025-03-30T22:17:12.220+0000] {processor.py:186} INFO - Started process (PID=182) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:17:12.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:17:12.226+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:17:12.225+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:17:12.274+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:17:12.274+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:17:12.314+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:17:12.314+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:17:12.424+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:17:12.454+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:17:12.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:17:12.466+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:17:12.466+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:17:12.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.275 seconds
[2025-03-30T22:17:42.885+0000] {processor.py:186} INFO - Started process (PID=184) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:17:42.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:17:42.890+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:17:42.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:17:42.931+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:17:42.931+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:17:42.968+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:17:42.969+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:17:43.083+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:17:43.099+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:17:43.099+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:17:43.111+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:17:43.111+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:17:43.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.245 seconds
[2025-03-30T22:18:13.250+0000] {processor.py:186} INFO - Started process (PID=186) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:18:13.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:18:13.256+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:18:13.256+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:18:13.301+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:18:13.302+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:18:13.340+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:18:13.340+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:18:13.456+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:18:13.471+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:18:13.471+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:18:13.483+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:18:13.483+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:18:13.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.253 seconds
[2025-03-30T22:18:43.896+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:18:43.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:18:43.902+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:18:43.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:18:43.944+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:18:43.944+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:18:43.992+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:18:43.992+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:18:44.100+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:18:44.116+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:18:44.115+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:18:44.127+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:18:44.127+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:18:44.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.261 seconds
[2025-03-30T22:19:14.290+0000] {processor.py:186} INFO - Started process (PID=190) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:19:14.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:19:14.297+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:19:14.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:19:14.352+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:19:14.352+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:19:14.394+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:19:14.394+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:19:14.506+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:19:14.522+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:19:14.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:19:14.533+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:19:14.533+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:19:14.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.266 seconds
[2025-03-30T22:19:44.891+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:19:44.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:19:44.897+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:19:44.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:19:44.940+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:19:44.940+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:19:44.972+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:19:44.972+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:19:45.091+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:19:45.108+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:19:45.107+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:19:45.119+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:19:45.119+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:19:45.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.262 seconds
[2025-03-30T22:20:15.307+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:20:15.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:20:15.315+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:20:15.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:20:15.375+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:20:15.376+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:20:15.411+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:20:15.411+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:20:15.541+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:20:15.563+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:20:15.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:20:15.576+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:20:15.576+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:20:15.585+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.297 seconds
[2025-03-30T22:20:45.866+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:20:45.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:20:45.884+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:20:45.884+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:20:45.938+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:20:45.939+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:20:45.971+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:20:45.972+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:20:46.093+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:20:46.113+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:20:46.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:20:46.125+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:20:46.125+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:20:46.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.288 seconds
[2025-03-30T22:21:16.358+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:21:16.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:21:16.363+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:21:16.362+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:21:16.405+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:21:16.405+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:21:16.437+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:21:16.437+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:21:16.541+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:21:16.558+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:21:16.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:21:16.570+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:21:16.570+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:21:16.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.232 seconds
[2025-03-30T22:21:46.768+0000] {processor.py:186} INFO - Started process (PID=200) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:21:46.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:21:46.775+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:21:46.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:21:46.858+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:21:46.859+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:21:46.907+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:21:46.907+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:21:47.079+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:21:47.112+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:21:47.112+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:21:47.127+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:21:47.126+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:21:47.135+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.377 seconds
[2025-03-30T22:22:17.339+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:22:17.341+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:22:17.346+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:22:17.346+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:22:17.399+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:22:17.399+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:22:17.436+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:22:17.436+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:22:17.550+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:22:17.567+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:22:17.567+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:22:17.580+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:22:17.580+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:22:17.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.273 seconds
[2025-03-30T22:22:47.914+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:22:47.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:22:47.920+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:22:47.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:22:47.979+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:22:47.979+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:22:48.013+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:22:48.013+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:22:48.148+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:22:48.165+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:22:48.165+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:22:48.177+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:22:48.177+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:22:48.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.312 seconds
[2025-03-30T22:23:18.319+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:23:18.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:23:18.324+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:23:18.324+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:23:18.377+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:23:18.377+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:23:18.418+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:23:18.418+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:23:18.528+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:23:18.571+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:23:18.570+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:23:18.588+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:23:18.588+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:23:18.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.287 seconds
[2025-03-30T22:23:48.931+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:23:48.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:23:48.936+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:23:48.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:23:48.979+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:23:48.979+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:23:49.024+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:23:49.024+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:23:49.135+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:23:49.152+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:23:49.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:23:49.164+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:23:49.164+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:23:49.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.258 seconds
[2025-03-30T22:24:19.318+0000] {processor.py:186} INFO - Started process (PID=210) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:24:19.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:24:19.326+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:24:19.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:24:19.387+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:24:19.388+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:24:19.428+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:24:19.429+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:24:19.536+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:24:19.571+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:24:19.571+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:24:19.586+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:24:19.585+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:24:19.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.292 seconds
[2025-03-30T22:24:50.036+0000] {processor.py:186} INFO - Started process (PID=212) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:24:50.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:24:50.041+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:24:50.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:24:50.090+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:24:50.090+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:24:50.135+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:24:50.135+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:24:50.257+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:24:50.279+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:24:50.279+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:24:50.295+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:24:50.295+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:24:50.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.297 seconds
[2025-03-30T22:25:20.429+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:25:20.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:25:20.435+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:25:20.435+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:25:20.486+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:25:20.486+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:25:20.530+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:25:20.530+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:25:20.663+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:25:20.682+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:25:20.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:25:20.694+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:25:20.694+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:25:20.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.301 seconds
[2025-03-30T22:25:51.044+0000] {processor.py:186} INFO - Started process (PID=216) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:25:51.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:25:51.048+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:25:51.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:25:51.086+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:25:51.087+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:25:51.136+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:25:51.137+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:25:51.244+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:25:51.273+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:25:51.273+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:25:51.291+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:25:51.291+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:25:51.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.264 seconds
[2025-03-30T22:26:21.398+0000] {processor.py:186} INFO - Started process (PID=218) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:26:21.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:26:21.408+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:26:21.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:26:21.455+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:26:21.455+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:26:21.495+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:26:21.496+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:26:21.606+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:26:21.623+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:26:21.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:26:21.635+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:26:21.634+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:26:21.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.259 seconds
[2025-03-30T22:26:52.085+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:26:52.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:26:52.092+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:26:52.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:26:52.153+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:26:52.154+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:26:52.206+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:26:52.207+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:26:52.315+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:26:52.345+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:26:52.345+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:26:52.357+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:26:52.357+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:26:52.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.295 seconds
[2025-03-30T22:27:22.521+0000] {processor.py:186} INFO - Started process (PID=222) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:27:22.523+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:27:22.529+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:27:22.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:27:22.595+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:27:22.596+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:27:22.647+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:27:22.647+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:27:22.772+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:27:22.794+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:27:22.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:27:22.809+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:27:22.809+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:27:22.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.313 seconds
[2025-03-30T22:27:53.116+0000] {processor.py:186} INFO - Started process (PID=224) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:27:53.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:27:53.140+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:27:53.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:27:53.199+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:27:53.200+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:27:53.238+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:27:53.238+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:27:53.379+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:27:53.403+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:27:53.403+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:27:53.418+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:27:53.418+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:27:53.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.322 seconds
[2025-03-30T22:28:23.805+0000] {processor.py:186} INFO - Started process (PID=226) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:28:23.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:28:23.820+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:28:23.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:28:23.874+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:28:23.875+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:28:23.913+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:28:23.913+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:28:24.028+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:28:24.050+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:28:24.050+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:28:24.064+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:28:24.064+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:28:24.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.282 seconds
[2025-03-30T22:28:54.197+0000] {processor.py:186} INFO - Started process (PID=228) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:28:54.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:28:54.205+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:28:54.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:28:54.252+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:28:54.252+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:28:54.298+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:28:54.298+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:28:54.416+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:28:54.440+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:28:54.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:28:54.454+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:28:54.454+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:28:54.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.289 seconds
[2025-03-30T22:29:24.907+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:29:24.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:29:24.914+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:29:24.913+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:29:24.972+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:29:24.973+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:29:25.019+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:29:25.020+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:29:25.129+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:29:25.166+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:29:25.166+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:29:25.182+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:29:25.181+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:29:25.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.298 seconds
[2025-03-30T22:29:55.254+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:29:55.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:29:55.276+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:29:55.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:29:55.321+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:29:55.321+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:29:55.374+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:29:55.374+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:29:55.496+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:29:55.520+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:29:55.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:29:55.553+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:29:55.553+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:29:55.561+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.317 seconds
[2025-03-30T22:30:25.972+0000] {processor.py:186} INFO - Started process (PID=234) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:30:25.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:30:25.979+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:30:25.978+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:30:26.044+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:30:26.044+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:30:26.085+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:30:26.086+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:30:26.206+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:30:26.228+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:30:26.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:30:26.256+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:30:26.255+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:30:26.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.304 seconds
[2025-03-30T22:30:56.453+0000] {processor.py:186} INFO - Started process (PID=236) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:30:56.456+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:30:56.460+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:30:56.460+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:30:56.526+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:30:56.527+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:30:56.578+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:30:56.578+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:30:56.699+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:30:56.720+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:30:56.720+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:30:56.734+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:30:56.734+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:30:56.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.307 seconds
[2025-03-30T22:31:27.062+0000] {processor.py:186} INFO - Started process (PID=238) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:31:27.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:31:27.070+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:31:27.069+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:31:27.114+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:31:27.114+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:31:27.161+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:31:27.161+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:31:27.282+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:31:27.304+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:31:27.304+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:31:27.319+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:31:27.319+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:31:27.328+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.286 seconds
[2025-03-30T22:31:57.417+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:31:57.424+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:31:57.442+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:31:57.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:31:57.488+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:31:57.488+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:31:57.539+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:31:57.539+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:31:57.678+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:31:57.700+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:31:57.700+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:31:57.716+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:31:57.716+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:31:57.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.323 seconds
[2025-03-30T22:32:28.116+0000] {processor.py:186} INFO - Started process (PID=242) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:32:28.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:32:28.122+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:32:28.122+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:32:28.165+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:32:28.165+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:32:28.222+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:32:28.222+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:32:28.338+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:32:28.359+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:32:28.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:32:28.374+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:32:28.374+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:32:28.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.284 seconds
[2025-03-30T22:32:58.554+0000] {processor.py:186} INFO - Started process (PID=244) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:32:58.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:32:58.561+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:32:58.560+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:32:58.607+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:32:58.607+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:32:58.645+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:32:58.645+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:32:58.767+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:32:58.799+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:32:58.799+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:32:58.814+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:32:58.814+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:32:58.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.287 seconds
[2025-03-30T22:33:29.192+0000] {processor.py:186} INFO - Started process (PID=246) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:33:29.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:33:29.196+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:33:29.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:33:29.251+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:33:29.252+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:33:29.301+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:33:29.302+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:33:29.412+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:33:29.449+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:33:29.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:33:29.462+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:33:29.462+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:33:29.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.290 seconds
[2025-03-30T22:33:59.860+0000] {processor.py:186} INFO - Started process (PID=248) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:33:59.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:33:59.869+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:33:59.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:33:59.926+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:33:59.926+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:33:59.972+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:33:59.973+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:34:00.095+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:34:00.118+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:34:00.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:34:00.142+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:34:00.142+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:34:00.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.306 seconds
[2025-03-30T22:34:30.280+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:34:30.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:34:30.287+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:34:30.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:34:30.346+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:34:30.346+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:34:30.386+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:34:30.386+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:34:30.507+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:34:30.527+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:34:30.527+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:34:30.541+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:34:30.541+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:34:30.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.281 seconds
[2025-03-30T22:35:00.922+0000] {processor.py:186} INFO - Started process (PID=252) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:35:00.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:35:00.927+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:35:00.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:35:00.988+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:35:00.989+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:35:01.029+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:35:01.030+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:35:01.151+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:35:01.180+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:35:01.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:35:01.195+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:35:01.194+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:35:01.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.293 seconds
[2025-03-30T22:35:31.342+0000] {processor.py:186} INFO - Started process (PID=254) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:35:31.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:35:31.353+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:35:31.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:35:31.394+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:35:31.394+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:35:31.444+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:35:31.445+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:35:31.576+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:35:31.597+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:35:31.596+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:35:31.610+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:35:31.610+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:35:31.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.288 seconds
[2025-03-30T22:36:02.001+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:36:02.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:36:02.006+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:36:02.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:36:02.041+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:36:02.042+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:36:02.091+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:36:02.091+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:36:02.214+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:36:02.235+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:36:02.235+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:36:02.249+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:36:02.249+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:36:02.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.293 seconds
[2025-03-30T22:36:32.413+0000] {processor.py:186} INFO - Started process (PID=258) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:36:32.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:36:32.420+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:36:32.419+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:36:32.460+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:36:32.460+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:36:32.503+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:36:32.503+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:36:32.618+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:36:32.639+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:36:32.639+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:36:32.652+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:36:32.652+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:36:32.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.269 seconds
[2025-03-30T22:37:03.076+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:37:03.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:37:03.080+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:37:03.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:37:03.129+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:37:03.129+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:37:03.170+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:37:03.170+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:37:03.291+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:37:03.311+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:37:03.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:37:03.325+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:37:03.325+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:37:03.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.278 seconds
[2025-03-30T22:37:33.523+0000] {processor.py:186} INFO - Started process (PID=262) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:37:33.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:37:33.532+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:37:33.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:37:33.654+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:37:33.654+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:37:33.778+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:37:33.779+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:37:33.933+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:37:33.973+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:37:33.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:37:33.989+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:37:33.989+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:37:34.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.500 seconds
[2025-03-30T22:37:41.137+0000] {processor.py:186} INFO - Started process (PID=264) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:37:41.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:37:41.142+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:37:41.142+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:37:41.150+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:37:41.149+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 31, in <module>
    extract = PythonOperator(
NameError: name 'PythonOperator' is not defined
[2025-03-30T22:37:41.150+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:37:41.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.073 seconds
[2025-03-30T22:38:11.565+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:38:11.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:38:11.572+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:38:11.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:38:11.579+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:38:11.578+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 31, in <module>
    extract = PythonOperator(
NameError: name 'PythonOperator' is not defined
[2025-03-30T22:38:11.579+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:38:11.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.055 seconds
[2025-03-30T22:38:31.926+0000] {processor.py:186} INFO - Started process (PID=266) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:38:31.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:38:31.931+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:38:31.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:38:31.937+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:38:31.937+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 31, in <module>
    extract = PythonOperator(
NameError: name 'PythonOperator' is not defined
[2025-03-30T22:38:31.938+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:38:31.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.052 seconds
[2025-03-30T22:38:57.482+0000] {processor.py:186} INFO - Started process (PID=267) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:38:57.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:38:57.486+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:38:57.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:38:57.493+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:38:57.493+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 31, in <module>
    extract = PythonOperator(
NameError: name 'PythonOperator' is not defined
[2025-03-30T22:38:57.494+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:38:57.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.066 seconds
[2025-03-30T22:39:21.826+0000] {processor.py:186} INFO - Started process (PID=268) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:39:21.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:39:21.832+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:39:21.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:39:21.842+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:39:21.841+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 31, in <module>
    extract = PythonOperator(
NameError: name 'PythonOperator' is not defined
[2025-03-30T22:39:21.842+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:39:21.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.075 seconds
[2025-03-30T22:39:52.296+0000] {processor.py:186} INFO - Started process (PID=269) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:39:52.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:39:52.299+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:39:52.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:39:52.317+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:39:52.316+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 31, in <module>
    extract = PythonOperator(
NameError: name 'PythonOperator' is not defined
[2025-03-30T22:39:52.317+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:39:52.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.053 seconds
[2025-03-30T22:40:22.780+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:40:22.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:40:22.782+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:40:22.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:40:22.787+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:40:22.786+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 31, in <module>
    extract = PythonOperator(
NameError: name 'PythonOperator' is not defined
[2025-03-30T22:40:22.787+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:40:22.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.039 seconds
[2025-03-30T22:40:53.210+0000] {processor.py:186} INFO - Started process (PID=271) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:40:53.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:40:53.214+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:40:53.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:40:53.221+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:40:53.220+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 31, in <module>
    extract = PythonOperator(
NameError: name 'PythonOperator' is not defined
[2025-03-30T22:40:53.221+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:40:53.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.052 seconds
[2025-03-30T22:41:23.649+0000] {processor.py:186} INFO - Started process (PID=272) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:41:23.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:41:23.662+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:41:23.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:41:23.675+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:41:23.674+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 31, in <module>
    extract = PythonOperator(
NameError: name 'PythonOperator' is not defined
[2025-03-30T22:41:23.676+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:41:23.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.061 seconds
[2025-03-30T22:41:54.056+0000] {processor.py:186} INFO - Started process (PID=273) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:41:54.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:41:54.058+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:41:54.058+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:41:54.063+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:41:54.063+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 31, in <module>
    extract = PythonOperator(
NameError: name 'PythonOperator' is not defined
[2025-03-30T22:41:54.064+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:41:54.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.054 seconds
[2025-03-30T22:42:14.412+0000] {processor.py:186} INFO - Started process (PID=274) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:42:14.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:42:14.415+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:42:14.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:42:14.422+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:42:14.421+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 31, in <module>
    extract = PythonOperator(
NameError: name 'PythonOperator' is not defined
[2025-03-30T22:42:14.422+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:42:14.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.049 seconds
[2025-03-30T22:42:44.838+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:42:44.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:42:44.842+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:42:44.842+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:42:44.848+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:42:44.847+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 31, in <module>
    extract = PythonOperator(
NameError: name 'PythonOperator' is not defined
[2025-03-30T22:42:44.849+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:42:44.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.057 seconds
[2025-03-30T22:43:15.316+0000] {processor.py:186} INFO - Started process (PID=276) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:43:15.317+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:43:15.319+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:43:15.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:43:15.326+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:43:15.325+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 31, in <module>
    extract = PythonOperator(
NameError: name 'PythonOperator' is not defined
[2025-03-30T22:43:15.326+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:43:15.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.053 seconds
[2025-03-30T22:43:45.810+0000] {processor.py:186} INFO - Started process (PID=277) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:43:45.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:43:45.813+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:43:45.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:43:45.818+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:43:45.817+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 31, in <module>
    extract = PythonOperator(
NameError: name 'PythonOperator' is not defined
[2025-03-30T22:43:45.818+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:43:45.834+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.057 seconds
[2025-03-30T22:44:04.136+0000] {processor.py:186} INFO - Started process (PID=278) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:44:04.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:44:04.139+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:44:04.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:44:04.199+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:44:04.200+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:44:04.232+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:44:04.232+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:44:04.360+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:44:04.517+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:44:04.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:44:04.542+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:44:04.542+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:44:04.552+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.427 seconds
[2025-03-30T22:44:34.992+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:44:34.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:44:34.997+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:44:34.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:44:35.041+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:44:35.041+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:44:35.079+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:44:35.079+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:44:35.196+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:44:35.233+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:44:35.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:44:35.251+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:44:35.251+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:44:35.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.307 seconds
[2025-03-30T22:45:05.394+0000] {processor.py:186} INFO - Started process (PID=282) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:45:05.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:45:05.398+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:45:05.397+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:45:05.446+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:45:05.447+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:45:05.481+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:45:05.481+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:45:05.589+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:45:05.621+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:45:05.621+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:45:05.636+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:45:05.635+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:45:05.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.266 seconds
[2025-03-30T22:45:36.155+0000] {processor.py:186} INFO - Started process (PID=284) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:45:36.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:45:36.158+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:45:36.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:45:36.213+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:45:36.213+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:45:36.243+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:45:36.243+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:45:36.351+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:45:36.347+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 8, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 5, in <module>
    parser.read(os.path.join(os.path.dirname(__file__), '../config/config.conf'))
  File "/usr/local/lib/python3.10/configparser.py", line 699, in read
    self._read(fp, filename)
  File "/usr/local/lib/python3.10/configparser.py", line 1087, in _read
    raise MissingSectionHeaderError(fpname, lineno, line)
configparser.MissingSectionHeaderError: File contains no section headers.
file: '/opt/airflow/utils/../config/config.conf', line: 1
'database]\n'
[2025-03-30T22:45:36.351+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:45:36.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.225 seconds
[2025-03-30T22:46:06.555+0000] {processor.py:186} INFO - Started process (PID=286) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:46:06.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:46:06.558+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:46:06.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:46:06.612+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:46:06.613+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:46:06.642+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:46:06.642+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:46:06.750+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:46:06.747+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 8, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 5, in <module>
    parser.read(os.path.join(os.path.dirname(__file__), '../config/config.conf'))
  File "/usr/local/lib/python3.10/configparser.py", line 699, in read
    self._read(fp, filename)
  File "/usr/local/lib/python3.10/configparser.py", line 1087, in _read
    raise MissingSectionHeaderError(fpname, lineno, line)
configparser.MissingSectionHeaderError: File contains no section headers.
file: '/opt/airflow/utils/../config/config.conf', line: 1
'database]\n'
[2025-03-30T22:46:06.750+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:46:06.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.232 seconds
[2025-03-30T22:46:37.117+0000] {processor.py:186} INFO - Started process (PID=288) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:46:37.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:46:37.120+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:46:37.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:46:37.151+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:46:37.151+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:46:37.176+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:46:37.177+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:46:37.268+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:46:37.266+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 8, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 5, in <module>
    parser.read(os.path.join(os.path.dirname(__file__), '../config/config.conf'))
  File "/usr/local/lib/python3.10/configparser.py", line 699, in read
    self._read(fp, filename)
  File "/usr/local/lib/python3.10/configparser.py", line 1087, in _read
    raise MissingSectionHeaderError(fpname, lineno, line)
configparser.MissingSectionHeaderError: File contains no section headers.
file: '/opt/airflow/utils/../config/config.conf', line: 1
'database]\n'
[2025-03-30T22:46:37.268+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:46:37.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.169 seconds
[2025-03-30T22:47:07.549+0000] {processor.py:186} INFO - Started process (PID=290) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:47:07.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:47:07.553+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:47:07.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:47:07.595+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:47:07.595+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:47:07.624+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:47:07.624+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:47:07.724+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:47:07.721+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 3, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 5, in <module>
    parser.read(os.path.join(os.path.dirname(__file__), '../config/config.conf'))
  File "/usr/local/lib/python3.10/configparser.py", line 699, in read
    self._read(fp, filename)
  File "/usr/local/lib/python3.10/configparser.py", line 1087, in _read
    raise MissingSectionHeaderError(fpname, lineno, line)
configparser.MissingSectionHeaderError: File contains no section headers.
file: '/opt/airflow/utils/../config/config.conf', line: 1
'database]\n'
[2025-03-30T22:47:07.724+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:47:07.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.227 seconds
[2025-03-30T22:47:38.026+0000] {processor.py:186} INFO - Started process (PID=292) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:47:38.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:47:38.029+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:47:38.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:47:38.069+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:47:38.069+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:47:38.098+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:47:38.098+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:47:38.199+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:47:38.197+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 3, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 5, in <module>
    parser.read(os.path.join(os.path.dirname(__file__), '../config/config.conf'))
  File "/usr/local/lib/python3.10/configparser.py", line 699, in read
    self._read(fp, filename)
  File "/usr/local/lib/python3.10/configparser.py", line 1087, in _read
    raise MissingSectionHeaderError(fpname, lineno, line)
configparser.MissingSectionHeaderError: File contains no section headers.
file: '/opt/airflow/utils/../config/config.conf', line: 1
'database]\n'
[2025-03-30T22:47:38.199+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:47:38.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.213 seconds
[2025-03-30T22:48:08.380+0000] {processor.py:186} INFO - Started process (PID=294) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:48:08.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:48:08.383+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:48:08.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:48:08.426+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:48:08.426+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:48:08.454+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:48:08.454+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:48:08.552+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:48:08.549+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 3, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 5, in <module>
    parser.read(os.path.join(os.path.dirname(__file__), '../config/config.conf'))
  File "/usr/local/lib/python3.10/configparser.py", line 699, in read
    self._read(fp, filename)
  File "/usr/local/lib/python3.10/configparser.py", line 1087, in _read
    raise MissingSectionHeaderError(fpname, lineno, line)
configparser.MissingSectionHeaderError: File contains no section headers.
file: '/opt/airflow/utils/../config/config.conf', line: 1
'database]\n'
[2025-03-30T22:48:08.553+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:48:08.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.225 seconds
[2025-03-30T22:48:39.012+0000] {processor.py:186} INFO - Started process (PID=296) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:48:39.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:48:39.015+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:48:39.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:48:39.055+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:48:39.055+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:48:39.098+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:48:39.099+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:48:39.223+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:48:39.219+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 3, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 5, in <module>
    parser.read(os.path.join(os.path.dirname(__file__), '../config/config.conf'))
  File "/usr/local/lib/python3.10/configparser.py", line 699, in read
    self._read(fp, filename)
  File "/usr/local/lib/python3.10/configparser.py", line 1087, in _read
    raise MissingSectionHeaderError(fpname, lineno, line)
configparser.MissingSectionHeaderError: File contains no section headers.
file: '/opt/airflow/utils/../config/config.conf', line: 1
'database]\n'
[2025-03-30T22:48:39.224+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:48:39.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.239 seconds
[2025-03-30T22:49:09.388+0000] {processor.py:186} INFO - Started process (PID=298) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:49:09.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:49:09.389+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:49:09.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:49:09.418+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:49:09.419+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:49:09.460+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:49:09.460+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:49:09.581+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:49:09.572+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 3, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 5, in <module>
    parser.read(os.path.join(os.path.dirname(__file__), '../config/config.conf'))
  File "/usr/local/lib/python3.10/configparser.py", line 699, in read
    self._read(fp, filename)
  File "/usr/local/lib/python3.10/configparser.py", line 1087, in _read
    raise MissingSectionHeaderError(fpname, lineno, line)
configparser.MissingSectionHeaderError: File contains no section headers.
file: '/opt/airflow/utils/../config/config.conf', line: 1
'database]\n'
[2025-03-30T22:49:09.582+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:49:09.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.317 seconds
[2025-03-30T22:49:39.967+0000] {processor.py:186} INFO - Started process (PID=300) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:49:39.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:49:39.973+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:49:39.971+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:49:40.028+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:49:40.029+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:49:40.058+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:49:40.058+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:49:40.201+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:49:40.199+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 3, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 5, in <module>
    parser.read(os.path.join(os.path.dirname(__file__), '../config/config.conf'))
  File "/usr/local/lib/python3.10/configparser.py", line 699, in read
    self._read(fp, filename)
  File "/usr/local/lib/python3.10/configparser.py", line 1087, in _read
    raise MissingSectionHeaderError(fpname, lineno, line)
configparser.MissingSectionHeaderError: File contains no section headers.
file: '/opt/airflow/utils/../config/config.conf', line: 1
'database]\n'
[2025-03-30T22:49:40.201+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:49:40.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.287 seconds
[2025-03-30T22:50:10.417+0000] {processor.py:186} INFO - Started process (PID=302) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:50:10.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:50:10.421+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:50:10.420+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:50:10.483+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:50:10.484+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:50:10.533+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:50:10.533+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:50:10.627+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:50:10.625+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 3, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 5, in <module>
    parser.read(os.path.join(os.path.dirname(__file__), '../config/config.conf'))
  File "/usr/local/lib/python3.10/configparser.py", line 699, in read
    self._read(fp, filename)
  File "/usr/local/lib/python3.10/configparser.py", line 1087, in _read
    raise MissingSectionHeaderError(fpname, lineno, line)
configparser.MissingSectionHeaderError: File contains no section headers.
file: '/opt/airflow/utils/../config/config.conf', line: 1
'database]\n'
[2025-03-30T22:50:10.627+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:50:10.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.238 seconds
[2025-03-30T22:50:41.011+0000] {processor.py:186} INFO - Started process (PID=304) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:50:41.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:50:41.014+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:50:41.014+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:50:41.056+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:50:41.057+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:50:41.099+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:50:41.099+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:50:41.189+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:50:41.187+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 3, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 5, in <module>
    parser.read(os.path.join(os.path.dirname(__file__), '../config/config.conf'))
  File "/usr/local/lib/python3.10/configparser.py", line 699, in read
    self._read(fp, filename)
  File "/usr/local/lib/python3.10/configparser.py", line 1087, in _read
    raise MissingSectionHeaderError(fpname, lineno, line)
configparser.MissingSectionHeaderError: File contains no section headers.
file: '/opt/airflow/utils/../config/config.conf', line: 1
'database]\n'
[2025-03-30T22:50:41.189+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:50:41.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.214 seconds
[2025-03-30T22:51:11.500+0000] {processor.py:186} INFO - Started process (PID=306) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:51:11.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:51:11.504+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:51:11.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:51:11.568+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:51:11.568+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:51:11.617+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:51:11.618+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:51:11.716+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:51:11.715+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 3, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 5, in <module>
    parser.read(os.path.join(os.path.dirname(__file__), '../config/config.conf'))
  File "/usr/local/lib/python3.10/configparser.py", line 699, in read
    self._read(fp, filename)
  File "/usr/local/lib/python3.10/configparser.py", line 1087, in _read
    raise MissingSectionHeaderError(fpname, lineno, line)
configparser.MissingSectionHeaderError: File contains no section headers.
file: '/opt/airflow/utils/../config/config.conf', line: 1
'database]\n'
[2025-03-30T22:51:11.717+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:51:11.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.246 seconds
[2025-03-30T22:51:41.986+0000] {processor.py:186} INFO - Started process (PID=308) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:51:41.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:51:41.989+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:51:41.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:51:42.041+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:51:42.041+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:51:42.080+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:51:42.081+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:51:42.186+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:51:42.278+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:51:42.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:51:42.290+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:51:42.290+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:51:42.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.340 seconds
[2025-03-30T22:52:12.441+0000] {processor.py:186} INFO - Started process (PID=310) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:52:12.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:52:12.444+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:52:12.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:52:12.471+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:52:12.472+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:52:12.510+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:52:12.510+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:52:12.590+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:52:12.603+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:52:12.603+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:52:12.613+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:52:12.613+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:52:12.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.190 seconds
[2025-03-30T22:52:43.057+0000] {processor.py:186} INFO - Started process (PID=312) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:52:43.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:52:43.061+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:52:43.060+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:52:43.096+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:52:43.097+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:52:43.130+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:52:43.131+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:52:43.238+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:52:43.267+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:52:43.267+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:52:43.281+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:52:43.281+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:52:43.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.266 seconds
[2025-03-30T22:53:13.471+0000] {processor.py:186} INFO - Started process (PID=314) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:53:13.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:53:13.475+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:53:13.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:53:13.518+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:53:13.518+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:53:13.545+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:53:13.546+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:53:13.662+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:53:13.682+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:53:13.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:53:13.708+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:53:13.708+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:53:13.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.261 seconds
[2025-03-30T22:53:44.114+0000] {processor.py:186} INFO - Started process (PID=316) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:53:44.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:53:44.117+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:53:44.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:53:44.168+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:53:44.168+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:53:44.204+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:53:44.204+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:53:44.306+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:53:44.325+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:53:44.325+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:53:44.349+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:53:44.349+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:53:44.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.256 seconds
[2025-03-30T22:54:14.579+0000] {processor.py:186} INFO - Started process (PID=318) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:54:14.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:54:14.581+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:54:14.581+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:54:14.628+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:54:14.629+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:54:14.667+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:54:14.667+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:54:14.780+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:54:14.804+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:54:14.803+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:54:14.829+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:54:14.829+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:54:14.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.271 seconds
[2025-03-30T22:54:45.263+0000] {processor.py:186} INFO - Started process (PID=320) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:54:45.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:54:45.266+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:54:45.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:54:45.307+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:54:45.307+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:54:45.348+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:54:45.348+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:54:45.467+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:54:45.493+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:54:45.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:54:45.507+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:54:45.507+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:54:45.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.270 seconds
[2025-03-30T22:55:07.607+0000] {processor.py:186} INFO - Started process (PID=322) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:55:07.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:55:07.609+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:55:07.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:55:07.699+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:55:07.700+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:55:07.741+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:55:07.741+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:55:07.892+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:55:07.923+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:55:07.922+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:55:07.938+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:55:07.937+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:55:07.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.352 seconds
[2025-03-30T22:55:38.137+0000] {processor.py:186} INFO - Started process (PID=324) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:55:38.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:55:38.139+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:55:38.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:55:38.174+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:55:38.175+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:55:38.201+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:55:38.202+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:55:38.374+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:55:38.411+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:55:38.411+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:55:38.453+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:55:38.452+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:55:38.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.334 seconds
[2025-03-30T22:56:08.773+0000] {processor.py:186} INFO - Started process (PID=326) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:56:08.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:56:08.776+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:56:08.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:56:08.814+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:56:08.814+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:56:08.848+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:56:08.848+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:56:08.940+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:56:08.957+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:56:08.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:56:08.969+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:56:08.969+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:56:08.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.213 seconds
[2025-03-30T22:56:39.109+0000] {processor.py:186} INFO - Started process (PID=328) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:56:39.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:56:39.112+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:56:39.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:56:39.164+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:56:39.165+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:56:39.204+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:56:39.204+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:56:39.300+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:56:39.317+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:56:39.317+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:56:39.328+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:56:39.328+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:56:39.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.242 seconds
[2025-03-30T22:57:09.814+0000] {processor.py:186} INFO - Started process (PID=330) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:57:09.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:57:09.819+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:57:09.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:57:09.877+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:57:09.878+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:57:09.914+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:57:09.914+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:57:10.003+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:57:10.020+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:57:10.020+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:57:10.031+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:57:10.031+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:57:10.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.239 seconds
[2025-03-30T22:57:40.208+0000] {processor.py:186} INFO - Started process (PID=332) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:57:40.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:57:40.219+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:57:40.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:57:40.273+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:57:40.273+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:57:40.312+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:57:40.312+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:57:40.404+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:57:40.420+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:57:40.420+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:57:40.432+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:57:40.432+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:57:40.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.248 seconds
[2025-03-30T22:58:10.862+0000] {processor.py:186} INFO - Started process (PID=334) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:58:10.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:58:10.865+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:58:10.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:58:10.918+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:58:10.919+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:58:10.964+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:58:10.964+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:58:11.054+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:58:11.075+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:58:11.075+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:58:11.087+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:58:11.087+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:58:11.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.244 seconds
[2025-03-30T22:58:41.387+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:58:41.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:58:41.390+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:58:41.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:58:41.432+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:58:41.432+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:58:41.477+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:58:41.478+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:58:41.564+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:58:41.582+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:58:41.582+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:58:41.593+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:58:41.593+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:58:41.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.252 seconds
[2025-03-30T22:59:11.999+0000] {processor.py:186} INFO - Started process (PID=338) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:59:12.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:59:12.001+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:59:12.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:59:12.043+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:59:12.044+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:59:12.086+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T22:59:12.086+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T22:59:12.176+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:59:12.195+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:59:12.195+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T22:59:12.207+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:59:12.206+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T22:59:12.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.226 seconds
[2025-03-30T22:59:42.442+0000] {processor.py:186} INFO - Started process (PID=340) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:59:42.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T22:59:42.448+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:59:42.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:59:42.457+0000] {logging_mixin.py:190} INFO - [2025-03-30T22:59:42.457+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 9
    "X-RapidAPI-Key": 047a26dcadmsh164bd9e65b8b78ap184943jsn4fe2d6e085f5,
                      ^
SyntaxError: leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers
[2025-03-30T22:59:42.458+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T22:59:42.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.076 seconds
[2025-03-30T23:00:12.819+0000] {processor.py:186} INFO - Started process (PID=341) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:00:12.820+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:00:12.821+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:00:12.821+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:00:12.858+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:00:12.858+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:00:12.888+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:00:12.888+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:00:12.995+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:00:13.016+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:00:13.016+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:00:13.029+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:00:13.029+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:00:13.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.225 seconds
[2025-03-30T23:00:43.232+0000] {processor.py:186} INFO - Started process (PID=343) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:00:43.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:00:43.236+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:00:43.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:00:43.278+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:00:43.279+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:00:43.307+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:00:43.307+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:00:43.419+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:00:43.439+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:00:43.439+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:00:43.457+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:00:43.457+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:00:43.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.246 seconds
[2025-03-30T23:01:13.824+0000] {processor.py:186} INFO - Started process (PID=345) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:01:13.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:01:13.828+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:01:13.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:01:13.871+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:01:13.871+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:01:13.898+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:01:13.898+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:01:14.008+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:01:14.046+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:01:14.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:01:14.063+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:01:14.063+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:01:14.072+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.285 seconds
[2025-03-30T23:01:44.258+0000] {processor.py:186} INFO - Started process (PID=347) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:01:44.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:01:44.261+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:01:44.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:01:44.300+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:01:44.300+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:01:44.327+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:01:44.328+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:01:44.454+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:01:44.477+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:01:44.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:01:44.490+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:01:44.490+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:01:44.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.270 seconds
[2025-03-30T23:02:14.913+0000] {processor.py:186} INFO - Started process (PID=349) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:02:14.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:02:14.916+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:02:14.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:02:14.960+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:02:14.961+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:02:14.989+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:02:14.989+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:02:15.095+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:02:15.119+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:02:15.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:02:15.132+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:02:15.132+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:02:15.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.239 seconds
[2025-03-30T23:02:45.274+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:02:45.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:02:45.277+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:02:45.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:02:45.328+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:02:45.328+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:02:45.359+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:02:45.359+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:02:45.478+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:02:45.499+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:02:45.499+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:02:45.528+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:02:45.527+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:02:45.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.275 seconds
[2025-03-30T23:03:15.905+0000] {processor.py:186} INFO - Started process (PID=353) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:03:15.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:03:15.907+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:03:15.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:03:15.947+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:03:15.947+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:03:15.995+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:03:15.996+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:03:16.112+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:03:16.134+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:03:16.134+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:03:16.148+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:03:16.148+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:03:16.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.287 seconds
[2025-03-30T23:03:46.363+0000] {processor.py:186} INFO - Started process (PID=355) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:03:46.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:03:46.367+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:03:46.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:03:46.424+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:03:46.424+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:03:46.455+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:03:46.455+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:03:46.598+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:03:46.628+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:03:46.628+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:03:46.646+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:03:46.646+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:03:46.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.314 seconds
[2025-03-30T23:04:17.017+0000] {processor.py:186} INFO - Started process (PID=357) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:04:17.018+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:04:17.019+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:04:17.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:04:17.082+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:04:17.082+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:04:17.129+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:04:17.129+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:04:17.235+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:04:17.273+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:04:17.273+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:04:17.289+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:04:17.289+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:04:17.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.291 seconds
[2025-03-30T23:04:47.441+0000] {processor.py:186} INFO - Started process (PID=359) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:04:47.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:04:47.443+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:04:47.443+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:04:47.450+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:04:47.450+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 10
    "x-rapidapi-key": 047a26dcadmsh164bd9e65b8b78ap184943jsn4fe2d6e085f5
                      ^
SyntaxError: leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers
[2025-03-30T23:04:47.451+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:04:47.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.061 seconds
[2025-03-30T23:05:17.757+0000] {processor.py:186} INFO - Started process (PID=360) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:05:17.758+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:05:17.759+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:05:17.759+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:05:17.793+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:05:17.794+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:05:17.820+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:05:17.820+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:05:17.986+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:05:18.014+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:05:18.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:05:18.038+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:05:18.038+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:05:18.056+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.313 seconds
[2025-03-30T23:05:48.167+0000] {processor.py:186} INFO - Started process (PID=362) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:05:48.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:05:48.171+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:05:48.170+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:05:48.207+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:05:48.207+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:05:48.232+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:05:48.233+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:05:48.309+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:05:48.323+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:05:48.323+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:05:48.333+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:05:48.333+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:05:48.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.188 seconds
[2025-03-30T23:06:18.625+0000] {processor.py:186} INFO - Started process (PID=364) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:06:18.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:06:18.633+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:06:18.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:06:18.680+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:06:18.680+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:06:18.709+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:06:18.709+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:06:18.820+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:06:18.856+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:06:18.856+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:06:18.872+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:06:18.872+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:06:18.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.284 seconds
[2025-03-30T23:06:49.106+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:06:49.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:06:49.111+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:06:49.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:06:49.163+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:06:49.163+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:06:49.191+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:06:49.192+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:06:49.320+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:06:49.428+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:06:49.427+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:06:49.439+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:06:49.438+0000] {dag.py:3262} INFO - Creating ORM DAG for etl_reddit_pipeline
[2025-03-30T23:06:49.450+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:06:49.450+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:06:49.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.370 seconds
[2025-03-30T23:07:19.724+0000] {processor.py:186} INFO - Started process (PID=368) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:07:19.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:07:19.728+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:07:19.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:07:19.784+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:07:19.784+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:07:19.823+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:07:19.823+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:07:19.951+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:07:19.975+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:07:19.975+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:07:19.998+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:07:19.998+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:07:20.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.304 seconds
[2025-03-30T23:07:50.227+0000] {processor.py:186} INFO - Started process (PID=370) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:07:50.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:07:50.230+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:07:50.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:07:50.270+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:07:50.271+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:07:50.328+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:07:50.328+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:07:50.462+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:07:50.482+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:07:50.482+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:07:50.497+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:07:50.497+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:07:50.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.299 seconds
[2025-03-30T23:08:20.833+0000] {processor.py:186} INFO - Started process (PID=372) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:08:20.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:08:20.836+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:08:20.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:08:20.905+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:08:20.907+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:08:20.958+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:08:20.958+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:08:21.065+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:08:21.095+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:08:21.095+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:08:21.111+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:08:21.111+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:08:21.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.297 seconds
[2025-03-30T23:08:51.319+0000] {processor.py:186} INFO - Started process (PID=374) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:08:51.320+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:08:51.321+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:08:51.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:08:51.356+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:08:51.357+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:08:51.408+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:08:51.408+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:08:51.532+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:08:51.565+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:08:51.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:08:51.579+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:08:51.579+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:08:51.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.298 seconds
[2025-03-30T23:09:21.994+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:09:21.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:09:21.997+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:09:21.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:09:22.041+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:09:22.041+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:09:22.105+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:09:22.106+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:09:22.215+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:09:22.239+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:09:22.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:09:22.267+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:09:22.266+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:09:22.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.312 seconds
[2025-03-30T23:09:52.331+0000] {processor.py:186} INFO - Started process (PID=378) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:09:52.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:09:52.334+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:09:52.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:09:52.396+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:09:52.397+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:09:52.437+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:09:52.437+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:09:52.555+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:09:52.581+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:09:52.581+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:09:52.595+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:09:52.595+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:09:52.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.284 seconds
[2025-03-30T23:10:22.683+0000] {processor.py:186} INFO - Started process (PID=380) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:10:22.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:10:22.691+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:10:22.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:10:22.743+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:10:22.743+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:10:22.801+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:10:22.802+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:10:22.940+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:10:22.981+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:10:22.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:10:23.003+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:10:23.003+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:10:23.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.353 seconds
[2025-03-30T23:10:53.400+0000] {processor.py:186} INFO - Started process (PID=382) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:10:53.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:10:53.403+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:10:53.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:10:53.450+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:10:53.450+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:10:53.499+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:10:53.500+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:10:53.654+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:10:53.704+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:10:53.704+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:10:53.733+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:10:53.733+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:10:53.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.356 seconds
[2025-03-30T23:11:23.813+0000] {processor.py:186} INFO - Started process (PID=384) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:11:23.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:11:23.817+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:11:23.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:11:23.888+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:11:23.888+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:11:23.931+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:11:23.931+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:11:24.049+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:11:24.089+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:11:24.089+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:11:24.105+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:11:24.105+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:11:24.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.320 seconds
[2025-03-30T23:11:54.437+0000] {processor.py:186} INFO - Started process (PID=386) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:11:54.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:11:54.440+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:11:54.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:11:54.489+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:11:54.489+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:11:54.533+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:11:54.533+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:11:54.641+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:11:54.686+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:11:54.686+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:11:54.705+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:11:54.705+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:11:54.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.300 seconds
[2025-03-30T23:12:24.803+0000] {processor.py:186} INFO - Started process (PID=388) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:12:24.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:12:24.818+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:12:24.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:12:24.871+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:12:24.872+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:12:24.933+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:12:24.934+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:12:25.056+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:12:25.081+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:12:25.081+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:12:25.097+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:12:25.097+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:12:25.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.315 seconds
[2025-03-30T23:12:55.447+0000] {processor.py:186} INFO - Started process (PID=390) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:12:55.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:12:55.450+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:12:55.450+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:12:55.545+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:12:55.546+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:12:55.767+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:12:55.768+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:12:55.901+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:12:55.945+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:12:55.944+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:12:55.966+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:12:55.966+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:12:55.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.540 seconds
[2025-03-30T23:13:26.430+0000] {processor.py:186} INFO - Started process (PID=392) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:13:26.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:13:26.434+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:13:26.433+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:13:26.486+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:13:26.488+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:13:26.543+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:13:26.543+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:13:26.678+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:13:26.721+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:13:26.721+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:13:26.743+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:13:26.743+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:13:26.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.349 seconds
[2025-03-30T23:13:56.838+0000] {processor.py:186} INFO - Started process (PID=394) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:13:56.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:13:56.843+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:13:56.843+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:13:56.938+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:13:56.939+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:13:56.988+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:13:56.989+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:13:57.101+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:13:57.129+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:13:57.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:13:57.158+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:13:57.158+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:13:57.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.354 seconds
[2025-03-30T23:14:27.623+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:14:27.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:14:27.625+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:14:27.625+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:14:27.682+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:14:27.682+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:14:27.723+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:14:27.723+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:14:27.841+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:14:27.869+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:14:27.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:14:27.883+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:14:27.883+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:14:27.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.308 seconds
[2025-03-30T23:14:58.033+0000] {processor.py:186} INFO - Started process (PID=398) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:14:58.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:14:58.038+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:14:58.037+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:14:58.093+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:14:58.093+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:14:58.140+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:14:58.141+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:14:58.255+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:14:58.277+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:14:58.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:14:58.292+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:14:58.292+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:14:58.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.282 seconds
[2025-03-30T23:15:28.672+0000] {processor.py:186} INFO - Started process (PID=400) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:15:28.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:15:28.675+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:15:28.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:15:28.752+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:15:28.752+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:15:28.809+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:15:28.809+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:15:28.925+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:15:28.948+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:15:28.948+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:15:28.961+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:15:28.961+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:15:28.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.311 seconds
[2025-03-30T23:15:59.081+0000] {processor.py:186} INFO - Started process (PID=402) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:15:59.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:15:59.085+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:15:59.085+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:15:59.140+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:15:59.141+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:15:59.178+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:15:59.178+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:15:59.295+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:15:59.318+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:15:59.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:15:59.331+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:15:59.331+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:15:59.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.278 seconds
[2025-03-30T23:16:29.724+0000] {processor.py:186} INFO - Started process (PID=404) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:16:29.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:16:29.727+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:16:29.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:16:29.803+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:16:29.803+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:16:29.855+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:16:29.855+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:16:29.959+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:16:29.992+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:16:29.992+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:16:30.021+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:16:30.021+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:16:30.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.319 seconds
[2025-03-30T23:17:00.169+0000] {processor.py:186} INFO - Started process (PID=406) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:17:00.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:17:00.173+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:17:00.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:17:00.224+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:17:00.225+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:17:00.270+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:17:00.270+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:17:00.376+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:17:00.397+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:17:00.397+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:17:00.412+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:17:00.412+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:17:00.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.268 seconds
[2025-03-30T23:17:30.807+0000] {processor.py:186} INFO - Started process (PID=408) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:17:30.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:17:30.821+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:17:30.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:17:30.951+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:17:30.951+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:17:30.993+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:17:30.993+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:17:31.111+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:17:31.151+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:17:31.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:17:31.166+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:17:31.166+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:17:31.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.406 seconds
[2025-03-30T23:18:01.578+0000] {processor.py:186} INFO - Started process (PID=410) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:18:01.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:18:01.584+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:18:01.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:18:01.624+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:18:01.624+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:18:01.654+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:18:01.655+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:18:01.808+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:18:01.837+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:18:01.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:18:01.853+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:18:01.853+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:18:01.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.314 seconds
[2025-03-30T23:18:32.011+0000] {processor.py:186} INFO - Started process (PID=412) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:18:32.013+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:18:32.014+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:18:32.014+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:18:32.068+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:18:32.069+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:18:32.099+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:18:32.099+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:18:32.247+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:18:32.271+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:18:32.270+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:18:32.285+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:18:32.285+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:18:32.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.306 seconds
[2025-03-30T23:19:02.728+0000] {processor.py:186} INFO - Started process (PID=414) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:19:02.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:19:02.731+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:19:02.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:19:02.779+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:19:02.779+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:19:02.808+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:19:02.808+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:19:02.940+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:19:02.963+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:19:02.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:19:02.977+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:19:02.977+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:19:02.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.268 seconds
[2025-03-30T23:19:33.136+0000] {processor.py:186} INFO - Started process (PID=416) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:19:33.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:19:33.141+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:19:33.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:19:33.191+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:19:33.191+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:19:33.218+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:19:33.219+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:19:33.348+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:19:33.370+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:19:33.370+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:19:33.396+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:19:33.396+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:19:33.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.284 seconds
[2025-03-30T23:20:03.863+0000] {processor.py:186} INFO - Started process (PID=418) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:20:03.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:20:03.867+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:20:03.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:20:03.928+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:20:03.928+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:20:03.966+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:20:03.966+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:20:04.085+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:20:04.108+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:20:04.108+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:20:04.122+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:20:04.122+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:20:04.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.288 seconds
[2025-03-30T23:20:34.265+0000] {processor.py:186} INFO - Started process (PID=420) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:20:34.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:20:34.270+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:20:34.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:20:34.331+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:20:34.331+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:20:34.360+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:20:34.360+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:20:34.480+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:20:34.512+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:20:34.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:20:34.532+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:20:34.532+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:20:34.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.290 seconds
[2025-03-30T23:21:04.988+0000] {processor.py:186} INFO - Started process (PID=422) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:21:04.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:21:04.991+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:21:04.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:21:05.042+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:21:05.043+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:21:05.086+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:21:05.087+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:21:05.222+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:21:05.266+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:21:05.266+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:21:05.282+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:21:05.282+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:21:05.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.316 seconds
[2025-03-30T23:21:35.436+0000] {processor.py:186} INFO - Started process (PID=424) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:21:35.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:21:35.441+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:21:35.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:21:35.482+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:21:35.482+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:21:35.514+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:21:35.514+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:21:35.637+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:21:35.659+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:21:35.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:21:35.679+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:21:35.679+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:21:35.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.273 seconds
[2025-03-30T23:22:06.069+0000] {processor.py:186} INFO - Started process (PID=426) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:22:06.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:22:06.072+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:22:06.072+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:22:06.123+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:22:06.123+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:22:06.155+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:22:06.155+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:22:06.268+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:22:06.291+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:22:06.291+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:22:06.318+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:22:06.318+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:22:06.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.268 seconds
[2025-03-30T23:22:36.456+0000] {processor.py:186} INFO - Started process (PID=428) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:22:36.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:22:36.459+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:22:36.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:22:36.519+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:22:36.519+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:22:36.549+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:22:36.549+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:22:36.670+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:22:36.693+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:22:36.693+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:22:36.708+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:22:36.708+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:22:36.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.283 seconds
[2025-03-30T23:23:07.115+0000] {processor.py:186} INFO - Started process (PID=430) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:23:07.116+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:23:07.118+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:23:07.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:23:07.172+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:23:07.173+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:23:07.207+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:23:07.207+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:23:07.314+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:23:07.337+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:23:07.337+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:23:07.352+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:23:07.351+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:23:07.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.260 seconds
[2025-03-30T23:23:37.614+0000] {processor.py:186} INFO - Started process (PID=432) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:23:37.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:23:37.619+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:23:37.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:23:37.679+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:23:37.679+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:23:37.726+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:23:37.727+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:23:37.835+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:23:37.859+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:23:37.859+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:23:37.881+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:23:37.881+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:23:37.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.302 seconds
[2025-03-30T23:24:08.310+0000] {processor.py:186} INFO - Started process (PID=434) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:24:08.312+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:24:08.313+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:24:08.313+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:24:08.369+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:24:08.369+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:24:08.406+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:24:08.406+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:24:08.518+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:24:08.552+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:24:08.552+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:24:08.570+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:24:08.570+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:24:08.578+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.279 seconds
[2025-03-30T23:24:38.727+0000] {processor.py:186} INFO - Started process (PID=436) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:24:38.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:24:38.733+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:24:38.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:24:38.796+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:24:38.796+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:24:38.824+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 8, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:24:38.825+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:24:38.971+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:24:38.993+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:24:38.993+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:24:39.007+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:24:39.007+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:24:39.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.305 seconds
[2025-03-30T23:24:51.156+0000] {processor.py:186} INFO - Started process (PID=438) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:24:51.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:24:51.160+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:24:51.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:24:51.211+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:24:51.212+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:24:51.254+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:24:51.254+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:24:51.380+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:24:51.374+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/configparser.py", line 791, in get
    value = d[option]
  File "/usr/local/lib/python3.10/collections/__init__.py", line 986, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.10/collections/__init__.py", line 978, in __missing__
    raise KeyError(key)
KeyError: 'rapidapi_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 3, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 27, in <module>
    RAPIDAPI_KEY = parser.get('api_keys', 'rapidapi_key')
  File "/usr/local/lib/python3.10/configparser.py", line 794, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'rapidapi_key' in section: 'api_keys'
[2025-03-30T23:24:51.381+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:24:51.415+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.272 seconds
[2025-03-30T23:25:21.615+0000] {processor.py:186} INFO - Started process (PID=440) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:25:21.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:25:21.618+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:25:21.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:25:21.680+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:25:21.680+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:25:21.717+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:25:21.718+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:25:21.841+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:25:21.837+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/configparser.py", line 791, in get
    value = d[option]
  File "/usr/local/lib/python3.10/collections/__init__.py", line 986, in __getitem__
    return self.__missing__(key)            # support subclasses that define __missing__
  File "/usr/local/lib/python3.10/collections/__init__.py", line 978, in __missing__
    raise KeyError(key)
KeyError: 'rapidapi_key'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/reddit_etl.py", line 3, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 27, in <module>
    RAPIDAPI_KEY = parser.get('api_keys', 'rapidapi_key')
  File "/usr/local/lib/python3.10/configparser.py", line 794, in get
    raise NoOptionError(option, section)
configparser.NoOptionError: No option 'rapidapi_key' in section: 'api_keys'
[2025-03-30T23:25:21.841+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:25:21.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.283 seconds
[2025-03-30T23:25:52.267+0000] {processor.py:186} INFO - Started process (PID=442) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:25:52.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:25:52.270+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:25:52.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:25:52.317+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:25:52.317+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:25:52.344+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:25:52.344+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:25:52.491+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:25:52.489+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
ImportError: cannot import name 'connect_reddit' from 'etls.reddit_etl' (/opt/airflow/etls/reddit_etl.py)
[2025-03-30T23:25:52.492+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:25:52.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.262 seconds
[2025-03-30T23:26:22.658+0000] {processor.py:186} INFO - Started process (PID=444) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:26:22.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:26:22.661+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:26:22.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:26:22.712+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:26:22.713+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:26:22.743+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:26:22.743+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:26:22.863+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:26:22.860+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/reddit_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 3, in <module>
    from etls.reddit_etl import connect_reddit, extract_posts, transform_data, load_data_to_csv
ImportError: cannot import name 'connect_reddit' from 'etls.reddit_etl' (/opt/airflow/etls/reddit_etl.py)
[2025-03-30T23:26:22.863+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:26:22.909+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.261 seconds
[2025-03-30T23:26:53.369+0000] {processor.py:186} INFO - Started process (PID=446) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:26:53.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:26:53.372+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:26:53.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:26:53.423+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:26:53.424+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:26:53.488+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:26:53.489+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:26:54.001+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:26:54.204+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:26:54.203+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:26:54.237+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:26:54.237+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:26:54.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.891 seconds
[2025-03-30T23:27:24.814+0000] {processor.py:186} INFO - Started process (PID=448) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:27:24.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:27:24.817+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:27:24.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:27:24.868+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:27:24.868+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:27:24.910+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:27:24.911+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:27:25.052+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:27:25.079+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:27:25.079+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:27:25.095+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:27:25.095+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:27:25.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.306 seconds
[2025-03-30T23:27:55.205+0000] {processor.py:186} INFO - Started process (PID=450) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:27:55.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:27:55.218+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:27:55.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:27:55.264+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:27:55.264+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:27:55.294+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:27:55.294+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:27:55.398+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:27:55.431+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:27:55.431+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:27:55.451+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:27:55.451+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:27:55.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.283 seconds
[2025-03-30T23:28:25.634+0000] {processor.py:186} INFO - Started process (PID=452) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:28:25.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:28:25.642+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:28:25.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:28:25.680+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:28:25.681+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:28:25.710+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:28:25.710+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:28:25.855+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:28:25.880+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:28:25.879+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:28:25.894+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:28:25.894+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:28:25.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.293 seconds
[2025-03-30T23:28:56.191+0000] {processor.py:186} INFO - Started process (PID=454) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:28:56.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:28:56.193+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:28:56.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:28:56.231+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:28:56.231+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:28:56.263+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:28:56.263+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:28:56.389+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:28:56.415+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:28:56.415+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:28:56.431+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:28:56.431+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:28:56.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.257 seconds
[2025-03-30T23:29:26.625+0000] {processor.py:186} INFO - Started process (PID=456) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:29:26.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:29:26.633+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:29:26.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:29:26.677+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:29:26.677+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:29:26.705+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:29:26.706+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:29:26.831+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:29:26.863+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:29:26.863+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:29:26.878+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:29:26.878+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:29:26.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.293 seconds
[2025-03-30T23:29:57.242+0000] {processor.py:186} INFO - Started process (PID=458) to work on /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:29:57.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/reddit_dag.py for tasks to queue
[2025-03-30T23:29:57.248+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:29:57.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:29:57.285+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 26, in <module>
    from pandas.compat import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/__init__.py", line 27, in <module>
    from pandas.compat.pyarrow import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/compat/pyarrow.py", line 8, in <module>
    import pyarrow as pa
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:29:57.285+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:29:57.312+0000] {logging_mixin.py:190} WARNING - 
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/airflow/.local/bin/airflow", line 8, in <module>
    sys.exit(main())
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/__main__.py", line 62, in main
    args.func(args)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/providers_configuration_loader.py", line 55, in wrapped_function
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 56, in scheduler
    run_command_with_daemon_option(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/daemon_utils.py", line 86, in run_command_with_daemon_option
    callback()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 59, in <lambda>
    callback=lambda: _run_scheduler_job(args),
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
    run_job(job=job_runner.job, execute_callable=job_runner._execute)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 421, in run_job
    return execute_job(job, execute_callable=execute_callable)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/job.py", line 450, in execute_job
    ret = execute_callable()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 995, in _execute
    self.processor_agent.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 172, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 247, in _run_processor_manager
    processor_manager.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 489, in start
    return self._run_parsing_loop()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 651, in _run_parsing_loop
    self.start_new_processes()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/traces/tracer.py", line 58, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 1239, in start_new_processes
    processor.start()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 263, in start
    process.start()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 918, in process_file
    dagbag = DagFileProcessor._get_dagbag(file_path)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 882, in _get_dagbag
    return DagBag(file_path, include_examples=False)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 173, in __init__
    self.collect_dags(
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 602, in collect_dags
    found_dags = self.process_file(filepath, only_if_updated=only_if_updated, safe_mode=safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 341, in process_file
    mods = self._load_modules_from_file(filepath, safe_mode)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 413, in _load_modules_from_file
    return parse(mod_name, filepath)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "/opt/airflow/dags/reddit_dag.py", line 10, in <module>
    from pipelines.reddit_pipeline import reddit_pipeline
  File "/opt/airflow/pipelines/reddit_pipeline.py", line 1, in <module>
    import pandas as pd
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/api.py", line 9, in <module>
    from pandas.core.dtypes.dtypes import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pandas/core/dtypes/dtypes.py", line 24, in <module>
    from pandas._libs import (
  File "/home/airflow/.local/lib/python3.10/site-packages/pyarrow/__init__.py", line 65, in <module>
    import pyarrow.lib as _lib
[2025-03-30T23:29:57.313+0000] {logging_mixin.py:190} WARNING - AttributeError: _ARRAY_API not found
[2025-03-30T23:29:57.429+0000] {processor.py:925} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/reddit_dag.py
[2025-03-30T23:29:57.469+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:29:57.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-30T23:29:57.484+0000] {logging_mixin.py:190} INFO - [2025-03-30T23:29:57.484+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_reddit_pipeline to 2025-03-30 00:00:00+00:00, run_after=2025-03-31 00:00:00+00:00
[2025-03-30T23:29:57.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/reddit_dag.py took 0.273 seconds
